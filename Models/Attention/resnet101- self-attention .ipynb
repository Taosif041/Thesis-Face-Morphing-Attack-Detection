{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28cc5ce6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-29T17:39:48.702665Z",
     "iopub.status.busy": "2024-05-29T17:39:48.701943Z",
     "iopub.status.idle": "2024-05-29T17:39:57.425355Z",
     "shell.execute_reply": "2024-05-29T17:39:57.424562Z"
    },
    "papermill": {
     "duration": 8.731181,
     "end_time": "2024-05-29T17:39:57.427679",
     "exception": false,
     "start_time": "2024-05-29T17:39:48.696498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoFeatureExtractor, ResNetForImageClassification\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fca72d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T17:39:57.436676Z",
     "iopub.status.busy": "2024-05-29T17:39:57.436118Z",
     "iopub.status.idle": "2024-05-29T17:39:57.440562Z",
     "shell.execute_reply": "2024-05-29T17:39:57.439765Z"
    },
    "papermill": {
     "duration": 0.010653,
     "end_time": "2024-05-29T17:39:57.442362",
     "exception": false,
     "start_time": "2024-05-29T17:39:57.431709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set the paths to your training, validation, and test directories\n",
    "# train_dir = '/kaggle/input/small-dataset/train'\n",
    "# val_dir = '/kaggle/input/small-dataset/val'\n",
    "# test_dir = '/kaggle/input/small-dataset/test'\n",
    "\n",
    "# # For the evaluation datasets\n",
    "# fm_dir = '/kaggle/input/mad-benchmark-small/FaceMorpher'\n",
    "# mg1_dir = '/kaggle/input/mad-benchmark-small/MIPGAN_I'\n",
    "# mg2_dir = '/kaggle/input/mad-benchmark-small/MIPGAN_II'\n",
    "# oc_dir = '/kaggle/input/mad-benchmark-small/OpenCV'\n",
    "# wm_dir = '/kaggle/input/mad-benchmark-small/Webmorph'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a0de15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T17:39:57.450414Z",
     "iopub.status.busy": "2024-05-29T17:39:57.449867Z",
     "iopub.status.idle": "2024-05-29T17:39:57.454360Z",
     "shell.execute_reply": "2024-05-29T17:39:57.453560Z"
    },
    "papermill": {
     "duration": 0.010471,
     "end_time": "2024-05-29T17:39:57.456190",
     "exception": false,
     "start_time": "2024-05-29T17:39:57.445719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the paths to your training, validation, and test directories\n",
    "train_dir = '/kaggle/input/morph-balanced/train'\n",
    "val_dir = '/kaggle/input/morph-balanced/val'\n",
    "# test_dir = '/kaggle/input/morph-splitted/test'\n",
    "\n",
    "# For the evaluation datasets\n",
    "fm_dir = '/kaggle/input/mad-benchmark/FaceMorpher'\n",
    "mg1_dir = '/kaggle/input/mad-benchmark/MIPGAN_I'\n",
    "mg2_dir = '/kaggle/input/mad-benchmark/MIPGAN_II'\n",
    "oc_dir = '/kaggle/input/mad-benchmark/OpenCV'\n",
    "wm_dir = '/kaggle/input/mad-benchmark/Webmorph'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc14e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T17:39:57.464083Z",
     "iopub.status.busy": "2024-05-29T17:39:57.463799Z",
     "iopub.status.idle": "2024-05-29T17:40:29.510157Z",
     "shell.execute_reply": "2024-05-29T17:40:29.509345Z"
    },
    "papermill": {
     "duration": 32.052897,
     "end_time": "2024-05-29T17:40:29.512511",
     "exception": false,
     "start_time": "2024-05-29T17:39:57.459614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transform)\n",
    "# test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "fm_loader = DataLoader(datasets.ImageFolder(fm_dir, transform=val_test_transform), batch_size=batch_size, shuffle=False)\n",
    "mg1_loader = DataLoader(datasets.ImageFolder(mg1_dir, transform=val_test_transform), batch_size=batch_size, shuffle=False)\n",
    "mg2_loader = DataLoader(datasets.ImageFolder(mg2_dir, transform=val_test_transform), batch_size=batch_size, shuffle=False)\n",
    "oc_loader = DataLoader(datasets.ImageFolder(oc_dir, transform=val_test_transform), batch_size=batch_size, shuffle=False)\n",
    "wm_loader = DataLoader(datasets.ImageFolder(wm_dir, transform=val_test_transform), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7f4c0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T17:40:29.521539Z",
     "iopub.status.busy": "2024-05-29T17:40:29.521238Z",
     "iopub.status.idle": "2024-05-29T17:40:31.997692Z",
     "shell.execute_reply": "2024-05-29T17:40:31.996809Z"
    },
    "papermill": {
     "duration": 2.483512,
     "end_time": "2024-05-29T17:40:32.000013",
     "exception": false,
     "start_time": "2024-05-29T17:40:29.516501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:01<00:00, 165MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a self-attention layer\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.key_conv = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.value_conv = nn.Conv2d(in_dim, in_dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(batch_size, -1, width * height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = nn.Softmax(dim=-1)(energy)\n",
    "        proj_value = self.value_conv(x).view(batch_size, -1, width * height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, width, height)\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "# Load pre-trained ResNet-101 model\n",
    "base_model = models.resnet101(pretrained=True)\n",
    "\n",
    "# Insert the attention layer before the final classifier\n",
    "class ResNetWithAttention(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(ResNetWithAttention, self).__init__()\n",
    "        self.base_model = nn.Sequential(*list(base_model.children())[:-2])  # Exclude the final linear layer\n",
    "        self.attention = SelfAttention(in_dim=2048)  # Attention layer with 2048 input channels\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_with_attention = ResNetWithAttention(base_model)\n",
    "model_with_attention.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model_with_attention.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b8772f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T17:40:32.011155Z",
     "iopub.status.busy": "2024-05-29T17:40:32.010614Z",
     "iopub.status.idle": "2024-05-29T18:53:50.494513Z",
     "shell.execute_reply": "2024-05-29T18:53:50.493420Z"
    },
    "papermill": {
     "duration": 4398.492171,
     "end_time": "2024-05-29T18:53:50.497162",
     "exception": false,
     "start_time": "2024-05-29T17:40:32.004991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [08:12<00:00,  1.52batch/s, accuracy=tensor(0.9859, device='cuda:0', dtype=torch.float64), loss=0.0357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0358 Acc: 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [01:27<00:00,  2.15batch/s, accuracy=tensor(1.9745, device='cuda:0', dtype=torch.float64), loss=0.0246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0124 Acc: 0.9952\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:12<00:00,  2.01batch/s, accuracy=tensor(0.9921, device='cuda:0', dtype=torch.float64), loss=0.0201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0201 Acc: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:57<00:00,  3.25batch/s, accuracy=tensor(1.9722, device='cuda:0', dtype=torch.float64), loss=0.0307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0155 Acc: 0.9940\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:14<00:00,  2.00batch/s, accuracy=tensor(0.9951, device='cuda:0', dtype=torch.float64), loss=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0104 Acc: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:54<00:00,  3.47batch/s, accuracy=tensor(1.9825, device='cuda:0', dtype=torch.float64), loss=0.00586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0030 Acc: 0.9992\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:06<00:00,  2.05batch/s, accuracy=tensor(0.9947, device='cuda:0', dtype=torch.float64), loss=0.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0129 Acc: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:53<00:00,  3.54batch/s, accuracy=tensor(1.9812, device='cuda:0', dtype=torch.float64), loss=0.013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0066 Acc: 0.9985\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:04<00:00,  2.06batch/s, accuracy=tensor(0.9970, device='cuda:0', dtype=torch.float64), loss=0.00538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0054 Acc: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:53<00:00,  3.51batch/s, accuracy=tensor(1.9815, device='cuda:0', dtype=torch.float64), loss=0.00876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0044 Acc: 0.9987\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:10<00:00,  2.02batch/s, accuracy=tensor(0.9945, device='cuda:0', dtype=torch.float64), loss=0.0125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0125 Acc: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:55<00:00,  3.36batch/s, accuracy=tensor(1.9762, device='cuda:0', dtype=torch.float64), loss=0.0223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0112 Acc: 0.9960\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:09<00:00,  2.03batch/s, accuracy=tensor(0.9971, device='cuda:0', dtype=torch.float64), loss=0.00458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0046 Acc: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:53<00:00,  3.53batch/s, accuracy=tensor(1.9821, device='cuda:0', dtype=torch.float64), loss=0.00435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0022 Acc: 0.9990\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:07<00:00,  2.04batch/s, accuracy=tensor(0.9963, device='cuda:0', dtype=torch.float64), loss=0.00753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0075 Acc: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:53<00:00,  3.50batch/s, accuracy=tensor(1.9838, device='cuda:0', dtype=torch.float64), loss=0.00271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0014 Acc: 0.9998\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:10<00:00,  2.03batch/s, accuracy=tensor(0.9981, device='cuda:0', dtype=torch.float64), loss=0.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0022 Acc: 0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:55<00:00,  3.39batch/s, accuracy=tensor(1.9841, device='cuda:0', dtype=torch.float64), loss=0.000746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0004 Acc: 1.0000\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Phase: 100%|██████████| 750/750 [06:09<00:00,  2.03batch/s, accuracy=tensor(0.9942, device='cuda:0', dtype=torch.float64), loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0136 Acc: 0.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val Phase: 100%|██████████| 188/188 [00:56<00:00,  3.34batch/s, accuracy=tensor(1.9828, device='cuda:0', dtype=torch.float64), loss=0.0103]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0052 Acc: 0.9993\n",
      "\n",
      "Best val Acc: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_model_wts = model_with_attention.state_dict()\n",
    "best_acc = 0.0\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model_with_attention.train()  # Set model to training mode\n",
    "        else:\n",
    "            model_with_attention.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with tqdm(total=len(train_loader if phase == 'train' else val_loader), desc=f'{phase} Phase', unit='batch') as pbar:\n",
    "            for inputs, labels in (train_loader if phase == 'train' else val_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.float().view(-1, 1).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model_with_attention(inputs)\n",
    "                    preds = torch.sigmoid(outputs).round()\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * inputs.size(0)),\n",
    "                                 accuracy=running_corrects.double() / ((pbar.n + 1) * inputs.size(0)))\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model_with_attention.state_dict()\n",
    "\n",
    "    print()\n",
    "\n",
    "model_with_attention.load_state_dict(best_model_wts)\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82636b32",
   "metadata": {
    "papermill": {
     "duration": 1.580021,
     "end_time": "2024-05-29T18:53:53.581470",
     "exception": false,
     "start_time": "2024-05-29T18:53:52.001449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883ce828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:53:56.667746Z",
     "iopub.status.busy": "2024-05-29T18:53:56.667401Z",
     "iopub.status.idle": "2024-05-29T18:57:45.135697Z",
     "shell.execute_reply": "2024-05-29T18:57:45.134837Z"
    },
    "papermill": {
     "duration": 230.525053,
     "end_time": "2024-05-29T18:57:45.611816",
     "exception": false,
     "start_time": "2024-05-29T18:53:55.086763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/1828690681.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, df], ignore_index=True)\n",
      "                                                           \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>APCER_0.01</th>\n",
       "      <th>APCER_0.1</th>\n",
       "      <th>APCER_0.2</th>\n",
       "      <th>BPCER_0.01</th>\n",
       "      <th>BPCER_0.1</th>\n",
       "      <th>BPCER_0.2</th>\n",
       "      <th>EER</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FaceMorpher</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIPGAN_I</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIPGAN_II</td>\n",
       "      <td>0.508509</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.343137</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>0.407520</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.766384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webmorph</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.642740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  APCER_0.01  APCER_0.1  APCER_0.2  BPCER_0.01  BPCER_0.1  \\\n",
       "0  FaceMorpher    0.139000   0.027000   0.014000    0.245098   0.014706   \n",
       "1     MIPGAN_I    0.576000   0.101000   0.026000    0.254902   0.088235   \n",
       "2    MIPGAN_II    0.508509   0.080080   0.029029    0.343137   0.068627   \n",
       "3       OpenCV    0.407520   0.054878   0.009146    0.186275   0.058824   \n",
       "4     Webmorph    0.614000   0.100000   0.030000    0.245098   0.088235   \n",
       "\n",
       "   BPCER_0.2       EER  Accuracy  \n",
       "0   0.000000  0.053922  0.769064  \n",
       "1   0.053922  0.098039  0.769064  \n",
       "2   0.039216  0.078431  0.767800  \n",
       "3   0.029412  0.068627  0.766384  \n",
       "4   0.058824  0.098039  0.642740  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "# Ensure the classifier model is correctly defined and loaded\n",
    "# Assuming 'classifier_model' is the model you want to evaluate\n",
    "# model_with_attention should be already defined and trained\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc='Evaluating', leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            true_labels.extend(labels.numpy())\n",
    "            predictions.extend(probs)\n",
    "\n",
    "    return np.array(true_labels), np.array(predictions)\n",
    "\n",
    "# Define functions to calculate APCER, BPCER, EER, and accuracy\n",
    "def calculate_apcer(true_labels, predictions, fixed_bpcer):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n",
    "    fpr_target = fixed_bpcer\n",
    "    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n",
    "    apcer = 1 - tpr[closest_fpr_index]\n",
    "    return apcer\n",
    "\n",
    "def calculate_bpcer(true_labels, predictions, fixed_apcer):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n",
    "    tpr_target = 1 - fixed_apcer\n",
    "    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n",
    "    bpcer = fpr[closest_tpr_index]\n",
    "    return bpcer\n",
    "\n",
    "def calculate_eer(true_labels, predictions):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n",
    "    eer_index = np.argmin(np.abs(fpr - (1 - tpr)))\n",
    "    eer = fpr[eer_index]\n",
    "    return eer\n",
    "\n",
    "def calculate_accuracy(true_labels, predictions):\n",
    "    binary_predictions = (predictions > 0.5).astype(int)\n",
    "    accuracy = np.mean(true_labels == binary_predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Compute metrics for a dataset\n",
    "def compute_metrics_for_dataset(model, data_loader, device, fixed_bpcer_values, fixed_apcer_values):\n",
    "    true_labels, predictions = evaluate_model(model, data_loader, device)\n",
    "    metrics = {\n",
    "        'APCER': {bpcer: calculate_apcer(true_labels, predictions, bpcer) for bpcer in fixed_bpcer_values},\n",
    "        'BPCER': {apcer: calculate_bpcer(true_labels, predictions, apcer) for apcer in fixed_apcer_values},\n",
    "        'EER': calculate_eer(true_labels, predictions),\n",
    "        'Accuracy': calculate_accuracy(true_labels, predictions)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Define fixed values for APCER and BPCER calculations\n",
    "fixed_bpcer_values = [0.01, 0.1, 0.2]\n",
    "fixed_apcer_values = [0.01, 0.1, 0.2]\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Dataset', 'APCER_0.01', 'APCER_0.1', 'APCER_0.2',\n",
    "                                   'BPCER_0.01', 'BPCER_0.1', 'BPCER_0.2', 'EER', 'Accuracy'])\n",
    "\n",
    "# Loaders dictionary\n",
    "loaders = {\n",
    "    'FaceMorpher': fm_loader,\n",
    "    'MIPGAN_I': mg1_loader,\n",
    "    'MIPGAN_II': mg2_loader,\n",
    "    'OpenCV': oc_loader,\n",
    "    'Webmorph': wm_loader\n",
    "}\n",
    "\n",
    "# Iterate through the loaders and compute metrics for each dataset\n",
    "for dataset_name, loader in loaders.items():\n",
    "    metrics = compute_metrics_for_dataset(model_with_attention, loader, device, fixed_bpcer_values, fixed_apcer_values)\n",
    "    \n",
    "    # Extract APCER and BPCER values for each fixed threshold\n",
    "    apcer_0_01 = metrics['APCER'][0.01]\n",
    "    apcer_0_1 = metrics['APCER'][0.1]\n",
    "    apcer_0_2 = metrics['APCER'][0.2]\n",
    "    \n",
    "    bpcer_0_01 = metrics['BPCER'][0.01]\n",
    "    bpcer_0_1 = metrics['BPCER'][0.1]\n",
    "    bpcer_0_2 = metrics['BPCER'][0.2]\n",
    "    \n",
    "    # Create a DataFrame for the current dataset metrics\n",
    "    df = pd.DataFrame({'Dataset': [dataset_name],\n",
    "                       'APCER_0.01': [apcer_0_01],\n",
    "                       'APCER_0.1': [apcer_0_1],\n",
    "                       'APCER_0.2': [apcer_0_2],\n",
    "                       'BPCER_0.01': [bpcer_0_01],\n",
    "                       'BPCER_0.1': [bpcer_0_1],\n",
    "                       'BPCER_0.2': [bpcer_0_2],\n",
    "                       'EER': [metrics['EER']],\n",
    "                       'Accuracy': [metrics['Accuracy']]})\n",
    "\n",
    "    # Concatenate the current dataset DataFrame with the results_df\n",
    "    results_df = pd.concat([results_df, df], ignore_index=True)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb0178c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:57:48.719787Z",
     "iopub.status.busy": "2024-05-29T18:57:48.718948Z",
     "iopub.status.idle": "2024-05-29T19:00:33.742844Z",
     "shell.execute_reply": "2024-05-29T19:00:33.741588Z"
    },
    "papermill": {
     "duration": 166.607499,
     "end_time": "2024-05-29T19:00:33.745705",
     "exception": false,
     "start_time": "2024-05-29T18:57:47.138206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating confusion matrix for dataset: FaceMorpher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 112   92]\n",
      " [   0 1000]]\n",
      "Calculating confusion matrix for dataset: MIPGAN_I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 112   92]\n",
      " [   0 1000]]\n",
      "Calculating confusion matrix for dataset: MIPGAN_II\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  92]\n",
      " [  2 997]]\n",
      "Calculating confusion matrix for dataset: OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  92]\n",
      " [  0 984]]\n",
      "Calculating confusion matrix for dataset: Webmorph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  92]\n",
      " [  1 499]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `model_with_attention` is your trained model\n",
    "# and `device` is already defined (e.g., `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`)\n",
    "\n",
    "# Function to calculate the confusion matrix\n",
    "def calculate_confusion_matrix(model, data_loader, device):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc='Calculating Confusion Matrix', leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().view(-1, 1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "    predicted_labels = np.concatenate(predicted_labels)\n",
    "\n",
    "    confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "    return confusion_mat\n",
    "\n",
    "# Assuming `loaders` is a dictionary of data loaders defined earlier\n",
    "data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\n",
    "dataset_names = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\n",
    "\n",
    "confusion_matrices = []\n",
    "\n",
    "# Calculate and store confusion matrices for each dataset\n",
    "for loader_idx, data_loader in enumerate(data_loaders):\n",
    "    dataset_name = dataset_names[loader_idx]\n",
    "    print(f\"Calculating confusion matrix for dataset: {dataset_name}\")\n",
    "\n",
    "    confusion_mat = calculate_confusion_matrix(model_with_attention, data_loader, device)\n",
    "    print(confusion_mat)\n",
    "    confusion_matrices.append(confusion_mat)\n",
    "\n",
    "# Print the confusion matrices\n",
    "# for dataset_name, confusion_mat in zip(dataset_names, confusion_matrices):\n",
    "#     print(f\"\\nConfusion Matrix - {dataset_name}:\")\n",
    "#     print(confusion_mat)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4910963,
     "sourceId": 8271362,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4924493,
     "sourceId": 8290075,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5050179,
     "sourceId": 8469777,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5083445,
     "sourceId": 8514818,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5091679,
     "sourceId": 8526502,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4851.104264,
   "end_time": "2024-05-29T19:00:37.104999",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-29T17:39:46.000735",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
