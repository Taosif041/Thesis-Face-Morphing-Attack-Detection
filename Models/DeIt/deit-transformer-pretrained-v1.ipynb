{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493},{"sourceId":8469777,"sourceType":"datasetVersion","datasetId":5050179},{"sourceId":8514818,"sourceType":"datasetVersion","datasetId":5083445}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2016.119707,"end_time":"2024-05-24T13:21:52.175361","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-24T12:48:16.055654","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0e7f0d4df06544c8ae9b4c4d94bbc5f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a29ebbcbd75c410e814a926548c134c3","placeholder":"​","style":"IPY_MODEL_890c1e2c36204029acf5cafa56ce4371","value":"config.json: 100%"}},"129923182d2b4268949ec284af191ad4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5730319b691d4aef9950fee079fb5065","placeholder":"​","style":"IPY_MODEL_31d7efcc1bdf4c0085d85337ea0a6416","value":" 346M/346M [00:02&lt;00:00, 100MB/s]"}},"2e0b72a1bc80473da2cd9e37459f8245":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e12c4880c8646b0955e7b58ce1be7e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d7efcc1bdf4c0085d85337ea0a6416":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"484908238f9c46c2abdd20ccf68582c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4df90f19a5ed43f992120a17a3590f4d","max":346293852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8112df48e928435e95c36d9695f89c6f","value":346293852}},"4df90f19a5ed43f992120a17a3590f4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5730319b691d4aef9950fee079fb5065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d0d3bd7fe92422386f036a2dd82e611":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69a28a2e9675420eb6c777599084ae25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef598b12d51044c5bd48214ac5acd76f","IPY_MODEL_484908238f9c46c2abdd20ccf68582c9","IPY_MODEL_129923182d2b4268949ec284af191ad4"],"layout":"IPY_MODEL_b71ca95586d04119a24d780253dd6ed8"}},"8112df48e928435e95c36d9695f89c6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8301b469b68d409da32aa3e9939141d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f81a08116fdc4e4fa92ccf4cb6b137c2","placeholder":"​","style":"IPY_MODEL_c349c07b7f384d9d9702957496b16dec","value":" 69.7k/69.7k [00:00&lt;00:00, 348kB/s]"}},"890c1e2c36204029acf5cafa56ce4371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a29ebbcbd75c410e814a926548c134c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a481b1e7e35d4588a48940481f448505":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e7f0d4df06544c8ae9b4c4d94bbc5f9","IPY_MODEL_ecb6c54063c44759960c54dc8ec5a188","IPY_MODEL_8301b469b68d409da32aa3e9939141d5"],"layout":"IPY_MODEL_2e0b72a1bc80473da2cd9e37459f8245"}},"b569eb6f1d324aa692a960a66e48fef7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b71ca95586d04119a24d780253dd6ed8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c349c07b7f384d9d9702957496b16dec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecb6c54063c44759960c54dc8ec5a188":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e12c4880c8646b0955e7b58ce1be7e2","max":69665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b569eb6f1d324aa692a960a66e48fef7","value":69665}},"ef598b12d51044c5bd48214ac5acd76f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffcee08015f1497b8e20bad5969eab76","placeholder":"​","style":"IPY_MODEL_5d0d3bd7fe92422386f036a2dd82e611","value":"model.safetensors: 100%"}},"f81a08116fdc4e4fa92ccf4cb6b137c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffcee08015f1497b8e20bad5969eab76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom transformers import DeiTForImageClassification, DeiTFeatureExtractor\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport numpy as np\nfrom sklearn.metrics import roc_curve\nimport pandas as pd\nfrom tqdm import tqdm\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":18.45,"end_time":"2024-05-24T12:48:37.181999","exception":false,"start_time":"2024-05-24T12:48:18.731999","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T22:07:42.487278Z","iopub.execute_input":"2024-05-25T22:07:42.488166Z","iopub.status.idle":"2024-05-25T22:07:42.493534Z","shell.execute_reply.started":"2024-05-25T22:07:42.488130Z","shell.execute_reply":"2024-05-25T22:07:42.492667Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # small\n# train_dir = '/kaggle/input/small-dataset/train'\n# val_dir = '/kaggle/input/small-dataset/val'\n# test_dir = '/kaggle/input/small-dataset/test'\n\n# fm_dir = '/kaggle/input/mad-benchmark-small/FaceMorpher'\n# mg1_dir = '/kaggle/input/mad-benchmark-small/MIPGAN_I'\n# mg2_dir = '/kaggle/input/mad-benchmark-small/MIPGAN_II'\n# oc_dir = '/kaggle/input/mad-benchmark-small/OpenCV'\n# wm_dir = '/kaggle/input/mad-benchmark-small/Webmorph'\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T22:07:42.495043Z","iopub.execute_input":"2024-05-25T22:07:42.495441Z","iopub.status.idle":"2024-05-25T22:07:42.505099Z","shell.execute_reply.started":"2024-05-25T22:07:42.495412Z","shell.execute_reply":"2024-05-25T22:07:42.504271Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'\n\n\nfm_dir = '/kaggle/input/mad-benchmark/FaceMorpher'\nmg1_dir = '/kaggle/input/mad-benchmark/MIPGAN_I'\nmg2_dir = '/kaggle/input/mad-benchmark/MIPGAN_II'\noc_dir = '/kaggle/input/mad-benchmark/OpenCV'\nwm_dir = '/kaggle/input/mad-benchmark/Webmorph'\n","metadata":{"papermill":{"duration":0.012328,"end_time":"2024-05-24T12:48:37.199052","exception":false,"start_time":"2024-05-24T12:48:37.186724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T22:07:42.532406Z","iopub.execute_input":"2024-05-25T22:07:42.532691Z","iopub.status.idle":"2024-05-25T22:07:42.537097Z","shell.execute_reply.started":"2024-05-25T22:07:42.532664Z","shell.execute_reply":"2024-05-25T22:07:42.536254Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Define transformations using Albumentations\ntrain_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_test_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\n# Create a custom dataset class to use Albumentations\nclass AlbumentationsDataset(datasets.ImageFolder):\n    def __init__(self, root, transform=None):\n        super(AlbumentationsDataset, self).__init__(root, transform=None)\n        self.transform = transform\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        sample = self.loader(path)\n        if self.transform is not None:\n            sample = np.array(sample)\n            sample = self.transform(image=sample)['image']\n        return sample, target","metadata":{"execution":{"iopub.status.busy":"2024-05-25T22:07:42.538685Z","iopub.execute_input":"2024-05-25T22:07:42.538935Z","iopub.status.idle":"2024-05-25T22:07:42.547914Z","shell.execute_reply.started":"2024-05-25T22:07:42.538915Z","shell.execute_reply":"2024-05-25T22:07:42.547127Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = AlbumentationsDataset(train_dir, transform=train_transform)\nval_dataset = AlbumentationsDataset(val_dir, transform=val_test_transform)\ntest_dataset = AlbumentationsDataset(test_dir, transform=val_test_transform)\n\n# Create data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# For the evaluation datasets\nfm_dataset = AlbumentationsDataset(fm_dir, transform=val_test_transform)\nmg1_dataset = AlbumentationsDataset(mg1_dir, transform=val_test_transform)\nmg2_dataset = AlbumentationsDataset(mg2_dir, transform=val_test_transform)\noc_dataset = AlbumentationsDataset(oc_dir, transform=val_test_transform)\nwm_dataset = AlbumentationsDataset(wm_dir, transform=val_test_transform)\n\n# Create data loaders for evaluation datasets\nfm_loader = DataLoader(fm_dataset, batch_size=batch_size, shuffle=False)\nmg1_loader = DataLoader(mg1_dataset, batch_size=batch_size, shuffle=False)\nmg2_loader = DataLoader(mg2_dataset, batch_size=batch_size, shuffle=False)\noc_loader = DataLoader(oc_dataset, batch_size=batch_size, shuffle=False)\nwm_loader = DataLoader(wm_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"papermill":{"duration":51.310187,"end_time":"2024-05-24T12:49:28.513487","exception":false,"start_time":"2024-05-24T12:48:37.203300","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T22:07:42.549016Z","iopub.execute_input":"2024-05-25T22:07:42.549340Z","iopub.status.idle":"2024-05-25T22:08:18.108417Z","shell.execute_reply.started":"2024-05-25T22:07:42.549311Z","shell.execute_reply":"2024-05-25T22:08:18.107614Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_name = 'facebook/deit-base-distilled-patch16-224'\ndeit_model = DeiTForImageClassification.from_pretrained(model_name)\n\n# Modify the classifier head for binary classification\nnum_features = deit_model.classifier.in_features\ndeit_model.classifier = nn.Sequential(\n    nn.Dropout(0.3),\n    nn.Linear(num_features, 1)\n)\n\n# Initialize the classifier model\nclassifier_model = deit_model\n\n# Move model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclassifier_model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.AdamW(classifier_model.parameters(), lr=1e-4, weight_decay=1e-2)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T22:08:18.110215Z","iopub.execute_input":"2024-05-25T22:08:18.110503Z","iopub.status.idle":"2024-05-25T22:08:18.739174Z","shell.execute_reply.started":"2024-05-25T22:08:18.110479Z","shell.execute_reply":"2024-05-25T22:08:18.738229Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    classifier_model.train()\n    running_loss = 0.0\n    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\")\n    for images, labels in train_loader_tqdm:\n        images, labels = images.to(device), labels.to(device)\n        labels = labels.float().unsqueeze(1)  # Convert labels to float and reshape for BCEWithLogitsLoss\n        \n        optimizer.zero_grad()\n        outputs = classifier_model(images)\n        logits = outputs.logits  # Extract logits from the output\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        train_loader_tqdm.set_postfix(loss=running_loss/len(train_loader))\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n    \n    # Validation\n    classifier_model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Validation\")\n    with torch.no_grad():\n        for images, labels in val_loader_tqdm:\n            images, labels = images.to(device), labels.to(device)\n            labels = labels.float().unsqueeze(1)\n            outputs = classifier_model(images)\n            logits = outputs.logits  # Extract logits from the output\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n            \n            predicted = torch.sigmoid(logits).round()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    val_accuracy = correct / total\n    print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {val_accuracy * 100}%')\n\nprint(\"Training complete\")\n","metadata":{"papermill":{"duration":0.022842,"end_time":"2024-05-24T12:49:33.459816","exception":false,"start_time":"2024-05-24T12:49:33.436974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T22:08:18.740606Z","iopub.execute_input":"2024-05-25T22:08:18.740949Z","iopub.status.idle":"2024-05-25T23:01:41.105714Z","shell.execute_reply.started":"2024-05-25T22:08:18.740917Z","shell.execute_reply":"2024-05-25T23:01:41.104735Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Epoch 1/5 Training: 100%|██████████| 750/750 [10:31<00:00,  1.19it/s, loss=0.00659]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Loss: 0.006594981925173064\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5 Validation: 100%|██████████| 250/250 [01:55<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 7.144523358874722e-06, Accuracy: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5 Training: 100%|██████████| 750/750 [08:51<00:00,  1.41it/s, loss=0.00543] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/5], Loss: 0.005425669205408364\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5 Validation: 100%|██████████| 250/250 [01:21<00:00,  3.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.0002386216320173844, Accuracy: 99.9875%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5 Training: 100%|██████████| 750/750 [08:52<00:00,  1.41it/s, loss=0.00277] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/5], Loss: 0.0027671900411690635\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5 Validation: 100%|██████████| 250/250 [01:22<00:00,  3.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.0001686474694952267, Accuracy: 99.9875%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5 Training: 100%|██████████| 750/750 [08:52<00:00,  1.41it/s, loss=1.31e-5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/5], Loss: 1.3092213251638896e-05\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5 Validation: 100%|██████████| 250/250 [01:22<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.00015412616501680532, Accuracy: 99.9875%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5 Training: 100%|██████████| 750/750 [08:50<00:00,  1.41it/s, loss=2.47e-6]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/5], Loss: 2.4699177638467517e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5 Validation: 100%|██████████| 250/250 [01:22<00:00,  3.04it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 9.59559011764668e-05, Accuracy: 99.9875%\nTraining complete\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing\nclassifier_model.eval()\ncorrect = 0\ntotal = 0\ntest_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\nwith torch.no_grad():\n    for images, labels in test_loader_tqdm:\n        images, labels = images.to(device), labels.to(device)\n        labels = labels.float().unsqueeze(1)\n        outputs = classifier_model(images)\n        logits = outputs.logits  # Extract logits from the output\n        predicted = torch.sigmoid(logits).round()\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\ntest_accuracy = correct / total\nprint(f'Test Accuracy: {test_accuracy * 100}%')\n","metadata":{"papermill":{"duration":1764.852619,"end_time":"2024-05-24T13:18:58.317352","exception":false,"start_time":"2024-05-24T12:49:33.464733","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T23:01:41.110744Z","iopub.execute_input":"2024-05-25T23:01:41.111024Z","iopub.status.idle":"2024-05-25T23:03:43.852627Z","shell.execute_reply.started":"2024-05-25T23:01:41.110998Z","shell.execute_reply":"2024-05-25T23:03:43.851544Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 250/250 [02:02<00:00,  2.04it/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the evaluation function\ndef evaluate_model(model, data_loader, device):\n    model.eval()\n    true_labels = []\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(data_loader, desc='Evaluating', leave=False):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            logits = outputs.logits.squeeze()  # Extract logits and then squeeze\n            probs = torch.sigmoid(logits).cpu().numpy()\n            true_labels.extend(labels.numpy())\n            predictions.extend(probs)\n\n    return np.array(true_labels), np.array(predictions)\n\n# Evaluate the model on multiple datasets\ndata_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\n\nfor loader in data_loaders:\n    true_labels, predictions = evaluate_model(classifier_model, loader, device)\n    accuracy = np.mean(np.array(true_labels) == (np.array(predictions) > 0.5))\n    results.append(accuracy)\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"papermill":{"duration":21.990714,"end_time":"2024-05-24T13:21:48.556000","exception":true,"start_time":"2024-05-24T13:21:26.565286","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T23:03:43.857372Z","iopub.execute_input":"2024-05-25T23:03:43.858044Z","iopub.status.idle":"2024-05-25T23:07:16.227049Z","shell.execute_reply.started":"2024-05-25T23:03:43.858012Z","shell.execute_reply":"2024-05-25T23:07:16.225728Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"                                                           ","output_type":"stream"},{"name":"stdout","text":"\nFinal Results:\nFaceMorpher: 0.1694\nMIPGAN_I: 0.1694\nMIPGAN_II: 0.1696\nOpenCV: 0.1717\nWebmorph: 0.2898\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation function\ndef evaluate_model(model, data_loader, device):\n    model.eval()\n    true_labels = []\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(data_loader, desc='Evaluating', leave=False):\n            inputs = inputs.to(device)\n            outputs = model(inputs).logits\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            true_labels.extend(labels.numpy())\n            predictions.extend(probs)\n\n    return np.array(true_labels), np.array(predictions)\n\n# Define functions to calculate APCER, BPCER, EER, and accuracy\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    eer_index = np.argmin(np.abs(fpr - (1 - tpr)))\n    eer = fpr[eer_index]\n    return eer\n\ndef calculate_accuracy(true_labels, predictions):\n    binary_predictions = (predictions > 0.5).astype(int)\n    accuracy = np.mean(true_labels == binary_predictions)\n    return accuracy\n\n# Compute metrics for a dataset\ndef compute_metrics_for_dataset(model, data_loader, device, fixed_bpcer_values, fixed_apcer_values):\n    true_labels, predictions = evaluate_model(model, data_loader, device)\n    metrics = {\n        'APCER': {bpcer: calculate_apcer(true_labels, predictions, bpcer) for bpcer in fixed_bpcer_values},\n        'BPCER': {apcer: calculate_bpcer(true_labels, predictions, apcer) for apcer in fixed_apcer_values},\n        'EER': calculate_eer(true_labels, predictions),\n        'Accuracy': calculate_accuracy(true_labels, predictions)\n    }\n    return metrics\n\n# Define fixed values for APCER and BPCER calculations\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\n\n# Create a DataFrame to store results\nresults_df = pd.DataFrame(columns=['Dataset', 'APCER_0.01', 'APCER_0.1', 'APCER_0.2',\n                                    'BPCER_0.01', 'BPCER_0.1', 'BPCER_0.2', 'EER', 'Accuracy'])\n\n# Loaders dictionary\nloaders = {\n    'FaceMorpher': fm_loader,\n    'MIPGAN_I': mg1_loader,\n    'MIPGAN_II': mg2_loader,\n    'OpenCV': oc_loader,\n    'Webmorph': wm_loader\n}\n\n# Iterate through the loaders and compute metrics for each dataset\nfor dataset_name, loader in loaders.items():\n    metrics = compute_metrics_for_dataset(classifier_model, loader, device, fixed_bpcer_values, fixed_apcer_values)\n    \n    # Extract APCER and BPCER values for each fixed threshold\n    apcer_0_01 = metrics['APCER'][0.01]\n    apcer_0_1 = metrics['APCER'][0.1]\n    apcer_0_2 = metrics['APCER'][0.2]\n    \n    bpcer_0_01 = metrics['BPCER'][0.01]\n    bpcer_0_1 = metrics['BPCER'][0.1]\n    bpcer_0_2 = metrics['BPCER'][0.2]\n    \n    # Create a DataFrame for the current dataset metrics\n    df = pd.DataFrame({'Dataset': [dataset_name],\n                       'APCER_0.01': [apcer_0_01],\n                       'APCER_0.1': [apcer_0_1],\n                       'APCER_0.2': [apcer_0_2],\n                       'BPCER_0.01': [bpcer_0_01],\n                       'BPCER_0.1': [bpcer_0_1],\n                       'BPCER_0.2': [bpcer_0_2],\n                       'EER': [metrics['EER']],\n                       'Accuracy': [metrics['Accuracy']]})\n\n    # Concatenate the current dataset DataFrame with the results_df\n    results_df = pd.concat([results_df, df], ignore_index=True)\n\n# Print or display the final DataFrame\n# print(results_df)\n\n# Export the results_df DataFrame to a CSV file\n# results_df.to_csv('evaluation_results.csv', index=False)\n\nresults_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:07:16.230630Z","iopub.execute_input":"2024-05-25T23:07:16.231029Z","iopub.status.idle":"2024-05-25T23:09:51.888002Z","shell.execute_reply.started":"2024-05-25T23:07:16.230996Z","shell.execute_reply":"2024-05-25T23:09:51.887088Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1932247866.py:96: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df = pd.concat([results_df, df], ignore_index=True)\n                                                           \r","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       Dataset  APCER_0.01  APCER_0.1  APCER_0.2  BPCER_0.01  BPCER_0.1  \\\n0  FaceMorpher    1.000000   1.000000   1.000000    0.000000   0.000000   \n1     MIPGAN_I    0.114000   0.005000   0.001000    0.039216   0.009804   \n2    MIPGAN_II    0.035035   0.003003   0.001001    0.024510   0.000000   \n3       OpenCV    0.653455   0.238821   0.088415    0.549020   0.176471   \n4     Webmorph    0.760000   0.290000   0.122000    0.558824   0.215686   \n\n   BPCER_0.2       EER  Accuracy  \n0   0.000000  0.000000  0.169435  \n1   0.000000  0.029412  0.169435  \n2   0.000000  0.019608  0.169576  \n3   0.117647  0.142157  0.171717  \n4   0.137255  0.161765  0.289773  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>APCER_0.01</th>\n      <th>APCER_0.1</th>\n      <th>APCER_0.2</th>\n      <th>BPCER_0.01</th>\n      <th>BPCER_0.1</th>\n      <th>BPCER_0.2</th>\n      <th>EER</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FaceMorpher</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.169435</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MIPGAN_I</td>\n      <td>0.114000</td>\n      <td>0.005000</td>\n      <td>0.001000</td>\n      <td>0.039216</td>\n      <td>0.009804</td>\n      <td>0.000000</td>\n      <td>0.029412</td>\n      <td>0.169435</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MIPGAN_II</td>\n      <td>0.035035</td>\n      <td>0.003003</td>\n      <td>0.001001</td>\n      <td>0.024510</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.019608</td>\n      <td>0.169576</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OpenCV</td>\n      <td>0.653455</td>\n      <td>0.238821</td>\n      <td>0.088415</td>\n      <td>0.549020</td>\n      <td>0.176471</td>\n      <td>0.117647</td>\n      <td>0.142157</td>\n      <td>0.171717</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Webmorph</td>\n      <td>0.760000</td>\n      <td>0.290000</td>\n      <td>0.122000</td>\n      <td>0.558824</td>\n      <td>0.215686</td>\n      <td>0.137255</td>\n      <td>0.161765</td>\n      <td>0.289773</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve, auc\nfrom tqdm import tqdm\n\n# Evaluation function\ndef evaluate_model(model, data_loader, device):\n    model.eval()\n    true_labels = []\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(data_loader, desc='Evaluating', leave=False):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            \n            # Adjust this line based on the actual structure of your model's output\n            if hasattr(outputs, 'logits'):\n                outputs = outputs.logits\n            elif hasattr(outputs, 'predictions'):\n                outputs = outputs.predictions\n\n            probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n            true_labels.extend(labels.numpy())\n            predictions.extend(probs)\n\n    return np.array(true_labels), np.array(predictions)\n\n# Define functions to calculate APCER, BPCER, EER, and accuracy\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    closest_fpr_index = np.argmin(np.abs(fpr - fixed_bpcer))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    closest_tpr_index = np.argmin(np.abs(tpr - (1 - fixed_apcer)))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    eer_index = np.argmin(np.abs(fpr - (1 - tpr)))\n    eer = fpr[eer_index]\n    return eer\n\ndef calculate_accuracy(true_labels, predictions):\n    binary_predictions = (predictions > 0.5).astype(int)\n    accuracy = np.mean(true_labels == binary_predictions)\n    return accuracy\n\n# Compute metrics for a dataset\ndef compute_metrics_for_dataset(model, data_loader, device, fixed_bpcer_values, fixed_apcer_values):\n    true_labels, predictions = evaluate_model(model, data_loader, device)\n    metrics = {\n        'APCER': {bpcer: calculate_apcer(true_labels, predictions, bpcer) for bpcer in fixed_bpcer_values},\n        'BPCER': {apcer: calculate_bpcer(true_labels, predictions, apcer) for apcer in fixed_apcer_values},\n        'EER': calculate_eer(true_labels, predictions),\n        'Accuracy': calculate_accuracy(true_labels, predictions)\n    }\n    return metrics\n\n# Define fixed values for APCER and BPCER calculations\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\n\n# Create a DataFrame to store results\nresults_df = pd.DataFrame(columns=['Dataset', 'APCER_0.01', 'APCER_0.1', 'APCER_0.2',\n                                    'BPCER_0.01', 'BPCER_0.1', 'BPCER_0.2', 'EER', 'Accuracy'])\n\n# Loaders dictionary (ensure these DataLoader objects are defined elsewhere in your code)\nloaders = {\n    'FaceMorpher': fm_loader,\n    'MIPGAN_I': mg1_loader,\n    'MIPGAN_II': mg2_loader,\n    'OpenCV': oc_loader,\n    'Webmorph': wm_loader\n}\n\n# Iterate through the loaders and compute metrics for each dataset\nfor dataset_name, loader in loaders.items():\n    metrics = compute_metrics_for_dataset(classifier_model, loader, device, fixed_bpcer_values, fixed_apcer_values)\n    \n    # Extract APCER and BPCER values for each fixed threshold\n    apcer_0_01 = metrics['APCER'][0.01]\n    apcer_0_1 = metrics['APCER'][0.1]\n    apcer_0_2 = metrics['APCER'][0.2]\n    \n    bpcer_0_01 = metrics['BPCER'][0.01]\n    bpcer_0_1 = metrics['BPCER'][0.1]\n    bpcer_0_2 = metrics['BPCER'][0.2]\n    \n    # Create a DataFrame for the current dataset metrics\n    df = pd.DataFrame({'Dataset': [dataset_name],\n                       'APCER_0.01': [apcer_0_01],\n                       'APCER_0.1': [apcer_0_1],\n                       'APCER_0.2': [apcer_0_2],\n                       'BPCER_0.01': [bpcer_0_01],\n                       'BPCER_0.1': [bpcer_0_1],\n                       'BPCER_0.2': [bpcer_0_2],\n                       'EER': [metrics['EER']],\n                       'Accuracy': [metrics['Accuracy']]})\n\n    # Concatenate the current dataset DataFrame with the results_df\n    results_df = pd.concat([results_df, df], ignore_index=True)\n\n\nresults_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:09:51.889479Z","iopub.execute_input":"2024-05-25T23:09:51.889846Z","iopub.status.idle":"2024-05-25T23:12:30.743994Z","shell.execute_reply.started":"2024-05-25T23:09:51.889817Z","shell.execute_reply":"2024-05-25T23:12:30.742991Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/776569406.py:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df = pd.concat([results_df, df], ignore_index=True)\n                                                           \r","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"       Dataset  APCER_0.01  APCER_0.1  APCER_0.2  BPCER_0.01  BPCER_0.1  \\\n0  FaceMorpher    1.000000   1.000000   1.000000    0.000000   0.000000   \n1     MIPGAN_I    0.114000   0.005000   0.001000    0.039216   0.009804   \n2    MIPGAN_II    0.035035   0.003003   0.001001    0.024510   0.000000   \n3       OpenCV    0.653455   0.238821   0.088415    0.549020   0.176471   \n4     Webmorph    0.760000   0.290000   0.122000    0.558824   0.215686   \n\n   BPCER_0.2       EER  Accuracy  \n0   0.000000  0.000000  0.169435  \n1   0.000000  0.029412  0.169435  \n2   0.000000  0.019608  0.169576  \n3   0.117647  0.142157  0.171717  \n4   0.137255  0.161765  0.289773  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>APCER_0.01</th>\n      <th>APCER_0.1</th>\n      <th>APCER_0.2</th>\n      <th>BPCER_0.01</th>\n      <th>BPCER_0.1</th>\n      <th>BPCER_0.2</th>\n      <th>EER</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FaceMorpher</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.169435</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MIPGAN_I</td>\n      <td>0.114000</td>\n      <td>0.005000</td>\n      <td>0.001000</td>\n      <td>0.039216</td>\n      <td>0.009804</td>\n      <td>0.000000</td>\n      <td>0.029412</td>\n      <td>0.169435</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MIPGAN_II</td>\n      <td>0.035035</td>\n      <td>0.003003</td>\n      <td>0.001001</td>\n      <td>0.024510</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.019608</td>\n      <td>0.169576</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OpenCV</td>\n      <td>0.653455</td>\n      <td>0.238821</td>\n      <td>0.088415</td>\n      <td>0.549020</td>\n      <td>0.176471</td>\n      <td>0.117647</td>\n      <td>0.142157</td>\n      <td>0.171717</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Webmorph</td>\n      <td>0.760000</td>\n      <td>0.290000</td>\n      <td>0.122000</td>\n      <td>0.558824</td>\n      <td>0.215686</td>\n      <td>0.137255</td>\n      <td>0.161765</td>\n      <td>0.289773</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# results_df.to_csv('evaluation_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:12:30.745543Z","iopub.execute_input":"2024-05-25T23:12:30.745904Z","iopub.status.idle":"2024-05-25T23:12:30.750479Z","shell.execute_reply.started":"2024-05-25T23:12:30.745877Z","shell.execute_reply":"2024-05-25T23:12:30.749256Z"},"trusted":true},"execution_count":29,"outputs":[]}]}