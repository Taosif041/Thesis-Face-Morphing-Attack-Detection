{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve\nimport pandas as pd\n# from apex import amp  # for mixed precision training\nfrom torchvision import models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T12:46:29.040541Z","iopub.execute_input":"2024-05-22T12:46:29.041197Z","iopub.status.idle":"2024-05-22T12:46:35.977673Z","shell.execute_reply.started":"2024-05-22T12:46:29.041164Z","shell.execute_reply":"2024-05-22T12:46:35.976858Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define transforms for data augmentation and normalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:46:35.979193Z","iopub.execute_input":"2024-05-22T12:46:35.979662Z","iopub.status.idle":"2024-05-22T12:46:35.987321Z","shell.execute_reply.started":"2024-05-22T12:46:35.979628Z","shell.execute_reply":"2024-05-22T12:46:35.986395Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:46:35.988418Z","iopub.execute_input":"2024-05-22T12:46:35.988740Z","iopub.status.idle":"2024-05-22T12:46:35.998346Z","shell.execute_reply.started":"2024-05-22T12:46:35.988716Z","shell.execute_reply":"2024-05-22T12:46:35.997591Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:46:36.000209Z","iopub.execute_input":"2024-05-22T12:46:36.000722Z","iopub.status.idle":"2024-05-22T12:47:11.953290Z","shell.execute_reply.started":"2024-05-22T12:46:36.000695Z","shell.execute_reply":"2024-05-22T12:47:11.952150Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False, num_workers=4)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:47:11.954504Z","iopub.execute_input":"2024-05-22T12:47:11.955006Z","iopub.status.idle":"2024-05-22T12:47:11.960643Z","shell.execute_reply.started":"2024-05-22T12:47:11.954963Z","shell.execute_reply":"2024-05-22T12:47:11.959770Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:47:11.961766Z","iopub.execute_input":"2024-05-22T12:47:11.962031Z","iopub.status.idle":"2024-05-22T12:47:11.992542Z","shell.execute_reply.started":"2024-05-22T12:47:11.962007Z","shell.execute_reply":"2024-05-22T12:47:11.991772Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define DenseNet model for binary classification\nclass DenseNetBinary(nn.Module):\n    def __init__(self):\n        super(DenseNetBinary, self).__init__()\n        self.model = models.densenet121(pretrained=True)\n        num_ftrs = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(num_ftrs, 1)  # Output layer with 1 neuron for binary classification\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Initialize the model\nmodel = DenseNetBinary().to(device)\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)  # Only train the classifier\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:47:11.993719Z","iopub.execute_input":"2024-05-22T12:47:11.994048Z","iopub.status.idle":"2024-05-22T12:47:12.801778Z","shell.execute_reply.started":"2024-05-22T12:47:11.994022Z","shell.execute_reply":"2024-05-22T12:47:12.800849Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 129MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 10\nbest_model_wts = model.state_dict()\nbest_acc = 0.0\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:47:12.803026Z","iopub.execute_input":"2024-05-22T12:47:12.803374Z","iopub.status.idle":"2024-05-22T12:47:12.814302Z","shell.execute_reply.started":"2024-05-22T12:47:12.803340Z","shell.execute_reply":"2024-05-22T12:47:12.813328Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()  # Set model to evaluate mode\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data with progress bar\n        with tqdm(total=len(dataloaders[phase]), desc=f'{phase} Phase', unit='batch') as pbar:\n            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.sigmoid(outputs).round()\n                    loss = criterion(outputs, labels.unsqueeze(1).float())\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.unsqueeze(1))\n\n                # Update progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * inputs.size(0)),\n                                 accuracy=running_corrects.double() / ((pbar.n + 1) * inputs.size(0)))\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Deep copy the model\n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = model.state_dict()\n\n    print()\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\nprint('Best val Acc: {:4f}'.format(best_acc))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:47:12.815666Z","iopub.execute_input":"2024-05-22T12:47:12.816014Z","iopub.status.idle":"2024-05-22T13:14:19.038313Z","shell.execute_reply.started":"2024-05-22T12:47:12.815989Z","shell.execute_reply":"2024-05-22T13:14:19.037125Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:24<00:00,  5.21batch/s, accuracy=tensor(0.9744, device='cuda:0', dtype=torch.float64), loss=0.0633]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0634 Acc: 0.9757\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:23<00:00, 10.52batch/s, accuracy=tensor(0.9701, device='cuda:0', dtype=torch.float64), loss=0.0767] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0770 Acc: 0.9740\n\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.22batch/s, accuracy=tensor(0.9857, device='cuda:0', dtype=torch.float64), loss=0.0369]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0370 Acc: 0.9870\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.58batch/s, accuracy=tensor(0.9801, device='cuda:0', dtype=torch.float64), loss=0.044]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0442 Acc: 0.9840\n\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:24<00:00,  5.21batch/s, accuracy=tensor(0.9882, device='cuda:0', dtype=torch.float64), loss=0.0279]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0279 Acc: 0.9895\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.55batch/s, accuracy=tensor(0.9795, device='cuda:0', dtype=torch.float64), loss=0.0455] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0457 Acc: 0.9834\n\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:24<00:00,  5.21batch/s, accuracy=tensor(0.9900, device='cuda:0', dtype=torch.float64), loss=0.0248]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0249 Acc: 0.9913\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.55batch/s, accuracy=tensor(0.9950, device='cuda:0', dtype=torch.float64), loss=0.00268] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0027 Acc: 0.9990\n\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.21batch/s, accuracy=tensor(0.9897, device='cuda:0', dtype=torch.float64), loss=0.0256]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0256 Acc: 0.9910\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.49batch/s, accuracy=tensor(0.9953, device='cuda:0', dtype=torch.float64), loss=0.00147] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0015 Acc: 0.9992\n\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.22batch/s, accuracy=tensor(0.9910, device='cuda:0', dtype=torch.float64), loss=0.0217]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0217 Acc: 0.9923\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.55batch/s, accuracy=tensor(0.9268, device='cuda:0', dtype=torch.float64), loss=0.227]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.2276 Acc: 0.9305\n\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.24batch/s, accuracy=tensor(0.9913, device='cuda:0', dtype=torch.float64), loss=0.0207]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0208 Acc: 0.9926\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.54batch/s, accuracy=tensor(0.9935, device='cuda:0', dtype=torch.float64), loss=0.00724] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0073 Acc: 0.9975\n\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.23batch/s, accuracy=tensor(0.9928, device='cuda:0', dtype=torch.float64), loss=0.0167]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0168 Acc: 0.9941\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.65batch/s, accuracy=tensor(0.9894, device='cuda:0', dtype=torch.float64), loss=0.0173]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0174 Acc: 0.9934\n\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:22<00:00,  5.25batch/s, accuracy=tensor(0.9933, device='cuda:0', dtype=torch.float64), loss=0.0137] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0137 Acc: 0.9947\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.81batch/s, accuracy=tensor(0.9934, device='cuda:0', dtype=torch.float64), loss=0.00665] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0067 Acc: 0.9974\n\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [02:23<00:00,  5.22batch/s, accuracy=tensor(0.9934, device='cuda:0', dtype=torch.float64), loss=0.0149] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0150 Acc: 0.9947\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:18<00:00, 13.79batch/s, accuracy=tensor(0.9854, device='cuda:0', dtype=torch.float64), loss=0.0303]  ","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0304 Acc: 0.9894\n\nBest val Acc: 0.999250\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nrunning_loss = 0.0\nrunning_corrects = 0\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\ntest_loss = running_loss / len(image_datasets['test'])\ntest_acc = running_corrects.double() / len(image_datasets['test'])\n\nprint(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:14:19.219433Z","iopub.execute_input":"2024-05-22T13:14:19.220084Z","iopub.status.idle":"2024-05-22T13:14:44.761394Z","shell.execute_reply.started":"2024-05-22T13:14:19.220048Z","shell.execute_reply":"2024-05-22T13:14:44.760309Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Test Loss: 0.0331 Acc: 0.9895\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 16\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:14:44.762848Z","iopub.execute_input":"2024-05-22T13:14:44.763142Z","iopub.status.idle":"2024-05-22T13:14:47.359553Z","shell.execute_reply.started":"2024-05-22T13:14:44.763113Z","shell.execute_reply":"2024-05-22T13:14:47.358777Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:14:47.360817Z","iopub.execute_input":"2024-05-22T13:14:47.361117Z","iopub.status.idle":"2024-05-22T13:14:47.379002Z","shell.execute_reply.started":"2024-05-22T13:14:47.361090Z","shell.execute_reply":"2024-05-22T13:14:47.378093Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DenseNetBinary(\n  (model): DenseNet(\n    (features): Sequential(\n      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu0): ReLU(inplace=True)\n      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (denseblock1): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition1): _Transition(\n        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock2): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition2): _Transition(\n        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock3): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer13): _DenseLayer(\n          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer14): _DenseLayer(\n          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer15): _DenseLayer(\n          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer16): _DenseLayer(\n          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer17): _DenseLayer(\n          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer18): _DenseLayer(\n          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer19): _DenseLayer(\n          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer20): _DenseLayer(\n          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer21): _DenseLayer(\n          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer22): _DenseLayer(\n          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer23): _DenseLayer(\n          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer24): _DenseLayer(\n          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition3): _Transition(\n        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock4): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer13): _DenseLayer(\n          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer14): _DenseLayer(\n          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer15): _DenseLayer(\n          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer16): _DenseLayer(\n          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (classifier): Linear(in_features=1024, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    results.append(test_accuracy.item())\n    losses.append(test_loss)\n\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:14:47.380257Z","iopub.execute_input":"2024-05-22T13:14:47.380581Z","iopub.status.idle":"2024-05-22T13:16:09.747347Z","shell.execute_reply.started":"2024-05-22T13:14:47.380549Z","shell.execute_reply":"2024-05-22T13:16:09.746254Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 1.6577 Acc: 0.6578\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 2.5322 Acc: 0.4684\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 2.2831 Acc: 0.4888\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 8.4672 Acc: 0.1742\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 9.5318 Acc: 0.2898\n\nFinal Results:\nFaceMorpher: 0.6578\nMIPGAN_I: 0.4684\nMIPGAN_II: 0.4888\nOpenCV: 0.1742\nWebmorph: 0.2898\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()  # Ensure the model is in evaluation mode\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        with torch.no_grad():  # Disable gradient computation\n            predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": apcer\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": bpcer\n        }\n        all_results.append(result)\n\n    # Calculate EER\n    eer = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:16:09.749062Z","iopub.execute_input":"2024-05-22T13:16:09.749726Z","iopub.status.idle":"2024-05-22T13:17:20.725289Z","shell.execute_reply.started":"2024-05-22T13:16:09.749686Z","shell.execute_reply":"2024-05-22T13:17:20.724178Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER Fixed APCER     BPCER       EER\n0   FaceMorpher        1.0%  0.057000         NaN       NaN       NaN\n1   FaceMorpher       10.0%  0.013000         NaN       NaN       NaN\n2   FaceMorpher       20.0%  0.007000         NaN       NaN       NaN\n3   FaceMorpher         NaN       NaN        1.0%  0.147059       NaN\n4   FaceMorpher         NaN       NaN       10.0%  0.000000       NaN\n5   FaceMorpher         NaN       NaN       20.0%  0.000000       NaN\n6   FaceMorpher         NaN       NaN         NaN       NaN  0.039216\n7      MIPGAN_I        1.0%  0.076000         NaN       NaN       NaN\n8      MIPGAN_I       10.0%  0.019000         NaN       NaN       NaN\n9      MIPGAN_I       20.0%  0.007000         NaN       NaN       NaN\n10     MIPGAN_I         NaN       NaN        1.0%  0.176471       NaN\n11     MIPGAN_I         NaN       NaN       10.0%  0.004902       NaN\n12     MIPGAN_I         NaN       NaN       20.0%  0.000000       NaN\n13     MIPGAN_I         NaN       NaN         NaN       NaN  0.049020\n14    MIPGAN_II        1.0%  0.061061         NaN       NaN       NaN\n15    MIPGAN_II       10.0%  0.018018         NaN       NaN       NaN\n16    MIPGAN_II       20.0%  0.009009         NaN       NaN       NaN\n17    MIPGAN_II         NaN       NaN        1.0%  0.156863       NaN\n18    MIPGAN_II         NaN       NaN       10.0%  0.004902       NaN\n19    MIPGAN_II         NaN       NaN       20.0%  0.000000       NaN\n20    MIPGAN_II         NaN       NaN         NaN       NaN  0.039216\n21       OpenCV        1.0%  0.548780         NaN       NaN       NaN\n22       OpenCV       10.0%  0.128049         NaN       NaN       NaN\n23       OpenCV       20.0%  0.052846         NaN       NaN       NaN\n24       OpenCV         NaN       NaN        1.0%  0.372549       NaN\n25       OpenCV         NaN       NaN       10.0%  0.107843       NaN\n26       OpenCV         NaN       NaN       20.0%  0.063725       NaN\n27       OpenCV         NaN       NaN         NaN       NaN  0.107843\n28     Webmorph        1.0%  0.756000         NaN       NaN       NaN\n29     Webmorph       10.0%  0.286000         NaN       NaN       NaN\n30     Webmorph       20.0%  0.146000         NaN       NaN       NaN\n31     Webmorph         NaN       NaN        1.0%  0.563725       NaN\n32     Webmorph         NaN       NaN       10.0%  0.250000       NaN\n33     Webmorph         NaN       NaN       20.0%  0.147059       NaN\n34     Webmorph         NaN       NaN         NaN       NaN  0.161765\n","output_type":"stream"}]}]}