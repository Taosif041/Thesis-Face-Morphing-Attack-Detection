{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493},{"sourceId":8479895,"sourceType":"datasetVersion","datasetId":5057673}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn.functional as F\n\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.checkpoint import checkpoint","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:53:46.384581Z","iopub.execute_input":"2024-05-23T12:53:46.385034Z","iopub.status.idle":"2024-05-23T12:53:46.391946Z","shell.execute_reply.started":"2024-05-23T12:53:46.384998Z","shell.execute_reply":"2024-05-23T12:53:46.390972Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters\nimg_size = 224  # Input image size\npatch_size = 16  # Size of image patches\nembed_dim = 768  # Embedding dimension\ndepth = 12  # Number of transformer encoder layers\nnum_heads = 12  # Number of attention heads\nmlp_ratio = 4.0  # Ratio of MLP hidden dimension to embedding dimension\nqkv_bias = True  # Add bias to the query, key, and value projections\ndropout_rate = 0.1  # Dropout rate\nnum_classes = 2  # Number of classes (binary classification)\nbatch_size = 32  # Batch size\nnum_epochs = 20  # Number of training epochs\nlearning_rate = 0.001  # Learning rate\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:53:46.394139Z","iopub.execute_input":"2024-05-23T12:53:46.394604Z","iopub.status.idle":"2024-05-23T12:53:46.405122Z","shell.execute_reply.started":"2024-05-23T12:53:46.394566Z","shell.execute_reply":"2024-05-23T12:53:46.403968Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'\n\n# Load your dataset\ntrain_set = datasets.ImageFolder(root=train_dir, transform=transform)\nval_set = datasets.ImageFolder(root=val_dir, transform=transform)\ntest_set = datasets.ImageFolder(root=test_dir, transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:53:46.407320Z","iopub.execute_input":"2024-05-23T12:53:46.407741Z","iopub.status.idle":"2024-05-23T12:54:12.491255Z","shell.execute_reply.started":"2024-05-23T12:53:46.407700Z","shell.execute_reply":"2024-05-23T12:54:12.490239Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# ViT implementation\nclass PatchEmbedding(nn.Module):\n    def __init__(self, in_channels=3, patch_size=16, embed_dim=768):\n        super().__init__()\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        x = self.proj(x)  # (batch_size, embed_dim, h//patch_size, w//patch_size)\n        x = x.flatten(2).transpose(1, 2)  # (batch_size, n_patches, embed_dim)\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, in_channels=3, num_classes=1000, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, qkv_bias=True, dropout_rate=0.1):\n        super().__init__()\n        self.patch_embed = PatchEmbedding(in_channels, patch_size, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n        self.pos_drop = nn.Dropout(dropout_rate)\n        self.transformer = Transformer(embed_dim, depth, num_heads, mlp_ratio, qkv_bias, dropout_rate)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n    def forward(self, x):\n        x = self.patch_embed(x)  # (batch_size, n_patches, embed_dim)\n        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)  # (batch_size, 1, embed_dim)\n        x = torch.cat((cls_tokens, x), dim=1)  # (batch_size, n_patches+1, embed_dim)\n        x = x + self.pos_embed  # (batch_size, n_patches+1, embed_dim)\n        x = self.pos_drop(x)\n        x = self.transformer(x)  # (batch_size, n_patches+1, embed_dim)\n        x = self.norm(x)\n        cls_final = x[:, 0]  # (batch_size, embed_dim)\n        output = self.head(cls_final)  # (batch_size, num_classes)\n        return output\n\nclass Transformer(nn.Module):\n    def __init__(self, embed_dim, depth, num_heads, mlp_ratio=4.0, qkv_bias=True, dropout_rate=0.1):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            TransformerLayer(embed_dim, num_heads, mlp_ratio, qkv_bias, dropout_rate)\n            for _ in range(depth)\n        ])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\nclass TransformerLayer(nn.Module):\n    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, qkv_bias=True, dropout_rate=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(embed_dim)\n        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout_rate, bias=qkv_bias)\n        self.norm2 = nn.LayerNorm(embed_dim)\n        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n        self.mlp = nn.Sequential(\n            nn.Linear(embed_dim, mlp_hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(mlp_hidden_dim, embed_dim),\n            nn.Dropout(dropout_rate)\n        )\n\n    def forward(self, x):\n        # Pass the same input to query, key, and value\n        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n        x = x + self.mlp(self.norm2(x))\n        return x# Initialize the model\n    \nmodel = ViT(img_size=img_size, patch_size=patch_size, in_channels=3, num_classes=num_classes,\n            embed_dim=embed_dim, depth=depth, num_heads=num_heads, mlp_ratio=mlp_ratio,\n            qkv_bias=qkv_bias, dropout_rate=dropout_rate).to(device)\n\n# Loss function and optimizer\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:54:12.493541Z","iopub.execute_input":"2024-05-23T12:54:12.494402Z","iopub.status.idle":"2024-05-23T12:54:13.575996Z","shell.execute_reply.started":"2024-05-23T12:54:12.494361Z","shell.execute_reply":"2024-05-23T12:54:13.574837Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# # Assuming your target labels are integers representing class indices\n# # Convert target labels to one-hot encoding\n# one_hot_targets = F.one_hot(labels, num_classes)\n\n# # Now one_hot_targets will have a size of [batch_size, num_classes]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:54:13.577880Z","iopub.execute_input":"2024-05-23T12:54:13.578332Z","iopub.status.idle":"2024-05-23T12:54:13.583142Z","shell.execute_reply.started":"2024-05-23T12:54:13.578295Z","shell.execute_reply":"2024-05-23T12:54:13.581977Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# criterion = nn.BCEWithLogitsLoss()\n\n# # Calculate loss\n# loss = criterion(outputs, one_hot_targets)\n\n# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:54:13.586670Z","iopub.execute_input":"2024-05-23T12:54:13.587730Z","iopub.status.idle":"2024-05-23T12:54:13.594781Z","shell.execute_reply.started":"2024-05-23T12:54:13.587685Z","shell.execute_reply":"2024-05-23T12:54:13.593588Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5  # Number of training epochs\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 20)\n\n    for batch_idx, (inputs, labels) in enumerate(train_loader, start=1):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # One-hot encode the target labels\n        labels = F.one_hot(labels, num_classes=num_classes).float()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if batch_idx % 100 == 0:\n            print(f\"Batch {batch_idx}/{len(train_loader)}, Loss: {running_loss / batch_idx:.4f}\")\n\n    epoch_loss = running_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n\n    # Evaluation on validation set\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    print(\"Evaluating on validation set...\")\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # One-hot encode the target labels\n            labels = F.one_hot(labels, num_classes=num_classes).float()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels.argmax(dim=1)).sum().item()\n\n        val_accuracy = 100 * correct / total\n        val_loss /= len(val_loader)\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n        print(\"-\" * 20)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T12:54:13.596231Z","iopub.execute_input":"2024-05-23T12:54:13.596637Z","iopub.status.idle":"2024-05-23T13:51:16.268057Z","shell.execute_reply.started":"2024-05-23T12:54:13.596607Z","shell.execute_reply":"2024-05-23T13:51:16.266916Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/5\n--------------------\nBatch 100/750, Loss: 0.8349\nBatch 200/750, Loss: 0.7544\nBatch 300/750, Loss: 0.7274\nBatch 400/750, Loss: 0.7139\nBatch 500/750, Loss: 0.7038\nBatch 600/750, Loss: 0.6979\nBatch 700/750, Loss: 0.6950\nEpoch 1/5, Loss: 0.6937\nEvaluating on validation set...\nValidation Loss: 0.6680, Validation Accuracy: 62.50%\n--------------------\nEpoch 2/5\n--------------------\nBatch 100/750, Loss: 0.6655\nBatch 200/750, Loss: 0.6687\nBatch 300/750, Loss: 0.6686\nBatch 400/750, Loss: 0.6694\nBatch 500/750, Loss: 0.6670\nBatch 600/750, Loss: 0.6678\nBatch 700/750, Loss: 0.6672\nEpoch 2/5, Loss: 0.6679\nEvaluating on validation set...\nValidation Loss: 0.6636, Validation Accuracy: 62.50%\n--------------------\nEpoch 3/5\n--------------------\nBatch 100/750, Loss: 0.6630\nBatch 200/750, Loss: 0.6673\nBatch 300/750, Loss: 0.6706\nBatch 400/750, Loss: 0.6702\nBatch 500/750, Loss: 0.6683\nBatch 600/750, Loss: 0.6670\nBatch 700/750, Loss: 0.6666\nEpoch 3/5, Loss: 0.6656\nEvaluating on validation set...\nValidation Loss: 0.6633, Validation Accuracy: 62.50%\n--------------------\nEpoch 4/5\n--------------------\nBatch 100/750, Loss: 0.6617\nBatch 200/750, Loss: 0.6654\nBatch 300/750, Loss: 0.6631\nBatch 400/750, Loss: 0.6624\nBatch 500/750, Loss: 0.6618\nBatch 600/750, Loss: 0.6629\nBatch 700/750, Loss: 0.6636\nEpoch 4/5, Loss: 0.6629\nEvaluating on validation set...\nValidation Loss: 0.6629, Validation Accuracy: 62.50%\n--------------------\nEpoch 5/5\n--------------------\nBatch 100/750, Loss: 0.6576\nBatch 200/750, Loss: 0.6601\nBatch 300/750, Loss: 0.6620\nBatch 400/750, Loss: 0.6620\nBatch 500/750, Loss: 0.6628\nBatch 600/750, Loss: 0.6630\nBatch 700/750, Loss: 0.6626\nEpoch 5/5, Loss: 0.6633\nEvaluating on validation set...\nValidation Loss: 0.6616, Validation Accuracy: 62.50%\n--------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation on test set\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * correct / total\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T13:51:16.269922Z","iopub.execute_input":"2024-05-23T13:51:16.270401Z","iopub.status.idle":"2024-05-23T13:53:49.299845Z","shell.execute_reply.started":"2024-05-23T13:51:16.270361Z","shell.execute_reply":"2024-05-23T13:53:49.298767Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Test Accuracy: 62.50%\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 32\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:55:27.723120Z","iopub.status.idle":"2024-05-23T13:55:27.723706Z","shell.execute_reply.started":"2024-05-23T13:55:27.723423Z","shell.execute_reply":"2024-05-23T13:55:27.723448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:53:49.788120Z","iopub.execute_input":"2024-05-23T13:53:49.788447Z","iopub.status.idle":"2024-05-23T13:53:49.800367Z","shell.execute_reply.started":"2024-05-23T13:53:49.788419Z","shell.execute_reply":"2024-05-23T13:53:49.799248Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"ViT(\n  (patch_embed): PatchEmbedding(\n    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n  )\n  (pos_drop): Dropout(p=0.1, inplace=False)\n  (transformer): Transformer(\n    (layers): ModuleList(\n      (0-11): 12 x TransformerLayer(\n        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.1, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (head): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\n# Assuming these variables are defined somewhere in your code\n# model, criterion, device, num_classes, data_loaders, results, losses\n\nfor loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # One-hot encode the target labels\n        labels = F.one_hot(labels, num_classes=num_classes).float()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Calculate predictions\n        preds = torch.sigmoid(outputs) > 0.5\n\n        # Update running metrics\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels).item()\n        total_samples += inputs.size(0)\n\n    # Calculate average loss and accuracy\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects / total_samples\n\n    results.append(test_accuracy)\n    losses.append(test_loss)\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:56:02.386696Z","iopub.execute_input":"2024-05-23T13:56:02.387209Z","iopub.status.idle":"2024-05-23T13:57:29.590395Z","shell.execute_reply.started":"2024-05-23T13:56:02.387175Z","shell.execute_reply":"2024-05-23T13:57:29.589043Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 0.9013 Acc: 0.3389\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 0.9013 Acc: 0.3389\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 0.9012 Acc: 0.3392\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 0.9001 Acc: 0.3434\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 0.8380 Acc: 0.5795\n\nFinal Results:\nFaceMorpher: 0.3389\nMIPGAN_I: 0.3389\nMIPGAN_II: 0.3392\nOpenCV: 0.3434\nWebmorph: 0.5795\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport numpy as np\nfrom sklearn.metrics import roc_curve\nfrom tqdm import tqdm\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 32\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\ndata_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:18:35.713385Z","iopub.execute_input":"2024-05-23T14:18:35.713792Z","iopub.status.idle":"2024-05-23T14:18:35.769280Z","shell.execute_reply.started":"2024-05-23T14:18:35.713762Z","shell.execute_reply":"2024-05-23T14:18:35.768282Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport numpy as np\nfrom sklearn.metrics import roc_curve\nfrom tqdm import tqdm\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 32\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\ndata_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\n\n# Define fixed BPCER and APCER values for evaluation\nfixed_bpcer_values = [0.01, 0.05, 0.1]\nfixed_apcer_values = [0.01, 0.05, 0.1]\n\n# Function to calculate metrics\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Evaluate the model on each dataset\ncriterion = torch.nn.BCEWithLogitsLoss()\nmodel.eval()\n\nresults = []\nlosses = []\nall_results = []\n\nfor loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    all_predictions = []\n    all_true_labels = []\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # One-hot encode the target labels\n        labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels_one_hot)\n\n        # Calculate predictions\n        preds = torch.sigmoid(outputs) > 0.5\n\n        # Update running metrics\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels_one_hot.data).item()\n        total_samples += inputs.size(0)\n\n        # Store predictions and labels\n        all_predictions.append(torch.sigmoid(outputs).detach().cpu().numpy())\n        all_true_labels.append(labels_one_hot.cpu().numpy())\n\n    # Calculate average loss and accuracy\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects / total_samples\n\n    results.append(test_accuracy)\n    losses.append(test_loss)\n\n    # Concatenate all predictions and true labels\n    predictions = np.concatenate(all_predictions).ravel()\n    true_labels = np.concatenate(all_true_labels).ravel()\n\n    # Ensure the lengths of true labels and predictions match\n    assert true_labels.shape[0] == predictions.shape[0], f\"Lengths of true labels ({true_labels.shape[0]}) and predictions ({predictions.shape[0]}) do not match\"\n\n    # Calculate APCER, BPCER, and EER\n    apcer_values = []\n    bpcer_values = []\n\n    for fixed_bpcer in fixed_bpcer_values:\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        apcer_values.append(apcer)\n\n    for fixed_apcer in fixed_apcer_values:\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        bpcer_values.append(bpcer)\n\n    eer = calculate_eer(true_labels, predictions)\n\n    # Store results\n    result = {\n        \"Dataset\": dataset_name,\n        \"Loss\": test_loss,\n        \"Accuracy\": test_accuracy,\n        \"APCER\": apcer_values,\n        \"BPCER\": bpcer_values,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n    # Print results\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} - APCER: {apcer_values}, BPCER: {bpcer_values}, EER: {eer:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nfor result in all_results:\n    print(result)\n\nimport pandas as pd\n\n# Convert the final results to a DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nprint(df_results)\ndf_results.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:31:08.929112Z","iopub.execute_input":"2024-05-23T14:31:08.929734Z","iopub.status.idle":"2024-05-23T14:32:35.940404Z","shell.execute_reply.started":"2024-05-23T14:31:08.929691Z","shell.execute_reply":"2024-05-23T14:32:35.939054Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 0.9013 Acc: 0.3389\nFaceMorpher - APCER: [1.0, 1.0, 1.0], BPCER: [1.0, 1.0, 1.0], EER: 0.8306\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 0.9013 Acc: 0.3389\nMIPGAN_I - APCER: [1.0, 1.0, 1.0], BPCER: [1.0, 1.0, 1.0], EER: 0.8306\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 0.9012 Acc: 0.3392\nMIPGAN_II - APCER: [1.0, 1.0, 1.0], BPCER: [1.0, 1.0, 1.0], EER: 0.8304\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 0.9001 Acc: 0.3434\nOpenCV - APCER: [1.0, 1.0, 1.0], BPCER: [1.0, 1.0, 1.0], EER: 0.8283\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 0.8380 Acc: 0.5795\nWebmorph - APCER: [1.0, 1.0, 1.0], BPCER: [1.0, 1.0, 1.0], EER: 0.7102\n\nFinal Results:\n{'Dataset': 'FaceMorpher', 'Loss': 0.9012874087621999, 'Accuracy': 0.3388704318936877, 'APCER': [1.0, 1.0, 1.0], 'BPCER': [1.0, 1.0, 1.0], 'EER': 0.8305647840531561}\n{'Dataset': 'MIPGAN_I', 'Loss': 0.9012874087621999, 'Accuracy': 0.3388704318936877, 'APCER': [1.0, 1.0, 1.0], 'BPCER': [1.0, 1.0, 1.0], 'EER': 0.8305647840531561}\n{'Dataset': 'MIPGAN_II', 'Loss': 0.9012133206611659, 'Accuracy': 0.33915211970074816, 'APCER': [1.0, 1.0, 1.0], 'BPCER': [1.0, 1.0, 1.0], 'EER': 0.830423940149626}\n{'Dataset': 'OpenCV', 'Loss': 0.9000870469041946, 'Accuracy': 0.3434343434343434, 'APCER': [1.0, 1.0, 1.0], 'BPCER': [1.0, 1.0, 1.0], 'EER': 0.8282828282828283}\n{'Dataset': 'Webmorph', 'Loss': 0.8379871276291934, 'Accuracy': 0.5795454545454546, 'APCER': [1.0, 1.0, 1.0], 'BPCER': [1.0, 1.0, 1.0], 'EER': 0.7102272727272727}\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:33:53.448696Z","iopub.execute_input":"2024-05-23T14:33:53.449466Z","iopub.status.idle":"2024-05-23T14:33:53.480733Z","shell.execute_reply.started":"2024-05-23T14:33:53.449430Z","shell.execute_reply":"2024-05-23T14:33:53.479678Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"\nFinal Results:\n       Dataset      Loss  Accuracy            APCER            BPCER       EER\n0  FaceMorpher  0.901287  0.338870  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830565\n1     MIPGAN_I  0.901287  0.338870  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830565\n2    MIPGAN_II  0.901213  0.339152  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830424\n3       OpenCV  0.900087  0.343434  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.828283\n4     Webmorph  0.837987  0.579545  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.710227\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"       Dataset      Loss  Accuracy            APCER            BPCER       EER\n0  FaceMorpher  0.901287  0.338870  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830565\n1     MIPGAN_I  0.901287  0.338870  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830565\n2    MIPGAN_II  0.901213  0.339152  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.830424\n3       OpenCV  0.900087  0.343434  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.828283\n4     Webmorph  0.837987  0.579545  [1.0, 1.0, 1.0]  [1.0, 1.0, 1.0]  0.710227","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>APCER</th>\n      <th>BPCER</th>\n      <th>EER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FaceMorpher</td>\n      <td>0.901287</td>\n      <td>0.338870</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>0.830565</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MIPGAN_I</td>\n      <td>0.901287</td>\n      <td>0.338870</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>0.830565</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MIPGAN_II</td>\n      <td>0.901213</td>\n      <td>0.339152</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>0.830424</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OpenCV</td>\n      <td>0.900087</td>\n      <td>0.343434</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>0.828283</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Webmorph</td>\n      <td>0.837987</td>\n      <td>0.579545</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>[1.0, 1.0, 1.0]</td>\n      <td>0.710227</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Assuming these variables are defined somewhere in your code\n# model, criterion, device, num_classes, data_loaders, results, losses, fixed_bpcer_values, fixed_apcer_values\n\nall_results = []\n\nfor loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    all_predictions = []\n    all_true_labels = []\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # One-hot encode the target labels\n        labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels_one_hot)\n\n        preds = torch.sigmoid(outputs) > 0.5\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels_one_hot.data)\n        total_samples += inputs.size(0)\n\n        all_predictions.append(torch.sigmoid(outputs).detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    # Concatenate all predictions and true labels\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Ensure the lengths of true labels and predictions match\n    assert true_labels.shape[0] == predictions.shape[0], f\"Lengths of true labels ({true_labels.shape[0]}) and predictions ({predictions.shape[0]}) do not match\"\n\n    # Flatten the arrays for ROC curve computation\n    true_labels_flat = true_labels.ravel()\n    predictions_flat = predictions.ravel()\n\n    # Calculate APCER, BPCER, and EER\n    apcer_values = []\n    bpcer_values = []\n\n    for fixed_bpcer in fixed_bpcer_values:\n        apcer = calculate_apcer(true_labels_flat, predictions_flat, fixed_bpcer)\n        apcer_values.append(apcer)\n\n    for fixed_apcer in fixed_apcer_values:\n        bpcer = calculate_bpcer(true_labels_flat, predictions_flat, fixed_apcer)\n        bpcer_values.append(bpcer)\n\n    eer = calculate_eer(true_labels_flat, predictions_flat)\n\n    # Store results\n    result = {\n        \"Dataset\": dataset_name,\n        \"Loss\": test_loss,\n        \"Accuracy\": test_accuracy.item(),\n        \"APCER\": apcer_values,\n        \"BPCER\": bpcer_values,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n    # Print results\n    print(f\"{dataset_name} - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} - APCER: {apcer_values}, BPCER: {bpcer_values}, EER: {eer:.4f}\")\n\n# Convert the final results to a DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:36:01.185081Z","iopub.execute_input":"2024-05-23T14:36:01.185465Z","iopub.status.idle":"2024-05-23T14:36:11.047386Z","shell.execute_reply.started":"2024-05-23T14:36:01.185431Z","shell.execute_reply":"2024-05-23T14:36:11.045631Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[65], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m bpcer_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fixed_bpcer \u001b[38;5;129;01min\u001b[39;00m fixed_bpcer_values:\n\u001b[0;32m---> 85\u001b[0m     apcer \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_apcer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_bpcer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     apcer_values\u001b[38;5;241m.\u001b[39mappend(apcer)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fixed_apcer \u001b[38;5;129;01min\u001b[39;00m fixed_apcer_values:\n","Cell \u001b[0;32mIn[65], line 11\u001b[0m, in \u001b[0;36mcalculate_apcer\u001b[0;34m(true_labels, predictions, fixed_bpcer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_apcer\u001b[39m(true_labels, predictions, fixed_bpcer):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate APCER at a fixed BPCER.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     fpr_target \u001b[38;5;241m=\u001b[39m fixed_bpcer\n\u001b[1;32m     13\u001b[0m     closest_fpr_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(fpr \u001b[38;5;241m-\u001b[39m fpr_target))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1204, 2408]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1204, 2408]","output_type":"error"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom torch.utils.data import DataLoader\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:03:19.300094Z","iopub.execute_input":"2024-05-23T14:03:19.300576Z","iopub.status.idle":"2024-05-23T14:03:19.312062Z","shell.execute_reply.started":"2024-05-23T14:03:19.300536Z","shell.execute_reply":"2024-05-23T14:03:19.310980Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\nall_results = []\n\n# Iterate over each dataset\nfor loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    dataset_name = names[loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    all_predictions = []\n    all_true_labels = []\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)  # No need to reshape or convert to float\n\n        # One-hot encode the target labels\n        labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels_one_hot)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels_one_hot.data)\n        total_samples += inputs.size(0)\n\n        all_predictions.append(torch.sigmoid(outputs).detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    # Concatenate all predictions and true labels\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Ensure the lengths of true labels and predictions match\n    assert true_labels.shape[0] == predictions.shape[0], f\"Lengths of true labels ({true_labels.shape[0]}) and predictions ({predictions.shape[0]}) do not match\"\n\n    # Flatten the arrays for ROC curve computation\n    true_labels_flat = true_labels.ravel()\n    predictions_flat = predictions.ravel()\n\n    # Calculate APCER, BPCER, and EER\n    apcer_values = []\n    bpcer_values = []\n\n    for fixed_bpcer in fixed_bpcer_values:\n        apcer = calculate_apcer(true_labels_flat, predictions_flat, fixed_bpcer)\n        apcer_values.append(apcer)\n\n    for fixed_apcer in fixed_apcer_values:\n        bpcer = calculate_bpcer(true_labels_flat, predictions_flat, fixed_apcer)\n        bpcer_values.append(bpcer)\n\n    eer = calculate_eer(true_labels_flat, predictions_flat)\n\n    # Store results\n    result = {\n        \"Dataset\": dataset_name,\n        \"Loss\": test_loss,\n        \"Accuracy\": test_accuracy.item(),\n        \"APCER\": apcer_values,\n        \"BPCER\": bpcer_values,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n    # Print results\n    print(f\"{dataset_name} - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} - APCER: {apcer_values}, BPCER: {bpcer_values}, EER: {eer:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nfor result in all_results:\n    print(result)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:15:48.973565Z","iopub.execute_input":"2024-05-23T14:15:48.974536Z","iopub.status.idle":"2024-05-23T14:15:58.780098Z","shell.execute_reply.started":"2024-05-23T14:15:48.974494Z","shell.execute_reply":"2024-05-23T14:15:58.778388Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m bpcer_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fixed_bpcer \u001b[38;5;129;01min\u001b[39;00m fixed_bpcer_values:\n\u001b[0;32m---> 83\u001b[0m     apcer \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_apcer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_bpcer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     apcer_values\u001b[38;5;241m.\u001b[39mappend(apcer)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fixed_apcer \u001b[38;5;129;01min\u001b[39;00m fixed_apcer_values:\n","Cell \u001b[0;32mIn[49], line 11\u001b[0m, in \u001b[0;36mcalculate_apcer\u001b[0;34m(true_labels, predictions, fixed_bpcer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_apcer\u001b[39m(true_labels, predictions, fixed_bpcer):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate APCER at a fixed BPCER.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     fpr_target \u001b[38;5;241m=\u001b[39m fixed_bpcer\n\u001b[1;32m     13\u001b[0m     closest_fpr_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(fpr \u001b[38;5;241m-\u001b[39m fpr_target))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1204, 2408]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1204, 2408]","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    closest_fpr_index = np.argmin(np.abs(fpr - fixed_bpcer))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    closest_tpr_index = np.argmin(np.abs(tpr - (1 - fixed_apcer)))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Assuming these variables are defined somewhere in your code\n# model, criterion, device, num_classes, data_loaders, results, losses, fixed_bpcer_values, fixed_apcer_values\n\nall_results = []\n\nfor loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    all_predictions = []\n    all_true_labels = []\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # One-hot encode the target labels\n        labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels_one_hot)\n\n        preds = torch.sigmoid(outputs) > 0.5\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels_one_hot.data)\n        total_samples += inputs.size(0)\n\n        all_predictions.append(torch.sigmoid(outputs).detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    # Concatenate all predictions and true labels\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Ensure the lengths of true labels and predictions match\n    assert true_labels.shape[0] == predictions.shape[0], f\"Lengths of true labels ({true_labels.shape[0]}) and predictions ({predictions.shape[0]}) do not match\"\n\n    # Flatten the arrays for ROC curve computation\n    true_labels_flat = true_labels.ravel()\n    predictions_flat = predictions.ravel()\n\n    # Calculate APCER, BPCER, and EER separately\n    apcer_values = [calculate_apcer(true_labels_flat, predictions_flat, fixed_bpcer) for fixed_bpcer in fixed_bpcer_values]\n    bpcer_values = [calculate_bpcer(true_labels_flat, predictions_flat, fixed_apcer) for fixed_apcer in fixed_apcer_values]\n    eer = calculate_eer(true_labels_flat, predictions_flat)\n\n    # Store results\n    result = {\n        \"Dataset\": dataset_name,\n        \"Loss\": test_loss,\n        \"Accuracy\": test_accuracy.item(),\n        \"APCER\": apcer_values,\n        \"BPCER\": bpcer_values,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n    # Print results\n    print(f\"{dataset_name} - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} - APCER: {apcer_values}, BPCER: {bpcer_values}, EER: {eer:.4f}\")\n\n# Convert the final results to a DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:44:36.898283Z","iopub.execute_input":"2024-05-23T14:44:36.898722Z","iopub.status.idle":"2024-05-23T14:44:46.719384Z","shell.execute_reply.started":"2024-05-23T14:44:36.898687Z","shell.execute_reply":"2024-05-23T14:44:46.717664Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m predictions_flat \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Calculate APCER, BPCER, and EER separately\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m apcer_values \u001b[38;5;241m=\u001b[39m [calculate_apcer(true_labels_flat, predictions_flat, fixed_bpcer) \u001b[38;5;28;01mfor\u001b[39;00m fixed_bpcer \u001b[38;5;129;01min\u001b[39;00m fixed_bpcer_values]\n\u001b[1;32m     77\u001b[0m bpcer_values \u001b[38;5;241m=\u001b[39m [calculate_bpcer(true_labels_flat, predictions_flat, fixed_apcer) \u001b[38;5;28;01mfor\u001b[39;00m fixed_apcer \u001b[38;5;129;01min\u001b[39;00m fixed_apcer_values]\n\u001b[1;32m     78\u001b[0m eer \u001b[38;5;241m=\u001b[39m calculate_eer(true_labels_flat, predictions_flat)\n","Cell \u001b[0;32mIn[66], line 76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m predictions_flat \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Calculate APCER, BPCER, and EER separately\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m apcer_values \u001b[38;5;241m=\u001b[39m [\u001b[43mcalculate_apcer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_bpcer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fixed_bpcer \u001b[38;5;129;01min\u001b[39;00m fixed_bpcer_values]\n\u001b[1;32m     77\u001b[0m bpcer_values \u001b[38;5;241m=\u001b[39m [calculate_bpcer(true_labels_flat, predictions_flat, fixed_apcer) \u001b[38;5;28;01mfor\u001b[39;00m fixed_apcer \u001b[38;5;129;01min\u001b[39;00m fixed_apcer_values]\n\u001b[1;32m     78\u001b[0m eer \u001b[38;5;241m=\u001b[39m calculate_eer(true_labels_flat, predictions_flat)\n","Cell \u001b[0;32mIn[66], line 10\u001b[0m, in \u001b[0;36mcalculate_apcer\u001b[0;34m(true_labels, predictions, fixed_bpcer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_apcer\u001b[39m(true_labels, predictions, fixed_bpcer):\n\u001b[0;32m---> 10\u001b[0m     fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     closest_fpr_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(fpr \u001b[38;5;241m-\u001b[39m fixed_bpcer))\n\u001b[1;32m     12\u001b[0m     apcer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tpr[closest_fpr_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1204, 2408]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1204, 2408]","output_type":"error"}]}]}