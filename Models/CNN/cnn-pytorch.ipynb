{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493},{"sourceId":8478764,"sourceType":"datasetVersion","datasetId":5056879},{"sourceId":8479895,"sourceType":"datasetVersion","datasetId":5057673},{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T23:22:09.099049Z","iopub.execute_input":"2024-05-21T23:22:09.099466Z","iopub.status.idle":"2024-05-21T23:22:09.444810Z","shell.execute_reply.started":"2024-05-21T23:22:09.099426Z","shell.execute_reply":"2024-05-21T23:22:09.443551Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Define transforms for data augmentation and normalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:31:45.536701Z","iopub.execute_input":"2024-05-21T22:31:45.537164Z","iopub.status.idle":"2024-05-21T22:31:45.545377Z","shell.execute_reply.started":"2024-05-21T22:31:45.537136Z","shell.execute_reply":"2024-05-21T22:31:45.544379Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:31:29.586119Z","iopub.execute_input":"2024-05-21T22:31:29.587021Z","iopub.status.idle":"2024-05-21T22:31:29.591528Z","shell.execute_reply.started":"2024-05-21T22:31:29.586983Z","shell.execute_reply":"2024-05-21T22:31:29.590578Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:33:22.477734Z","iopub.execute_input":"2024-05-21T22:33:22.478461Z","iopub.status.idle":"2024-05-21T22:34:18.615007Z","shell.execute_reply.started":"2024-05-21T22:33:22.478426Z","shell.execute_reply":"2024-05-21T22:34:18.613767Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=512, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=512, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=512, shuffle=False, num_workers=4)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:10:27.442705Z","iopub.execute_input":"2024-05-21T23:10:27.443142Z","iopub.status.idle":"2024-05-21T23:10:27.449167Z","shell.execute_reply.started":"2024-05-21T23:10:27.443107Z","shell.execute_reply":"2024-05-21T23:10:27.447996Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define the CNN model for binary classification\nclass BinaryCNN(nn.Module):\n    def __init__(self):\n        super(BinaryCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(64 * 28 * 28, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, 1)  # Output layer with 1 neuron for binary classification\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n    \n# Initialize the model, loss function, and optimizer\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = BinaryCNN().to(device)\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:39:25.993623Z","iopub.execute_input":"2024-05-21T22:39:25.993954Z","iopub.status.idle":"2024-05-21T22:39:26.516390Z","shell.execute_reply.started":"2024-05-21T22:39:25.993915Z","shell.execute_reply":"2024-05-21T22:39:26.515439Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Training and evaluation loop\nnum_epochs = 10\nbest_model_wts = model.state_dict()\nbest_acc = 0.0\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:39:26.518257Z","iopub.execute_input":"2024-05-21T22:39:26.518624Z","iopub.status.idle":"2024-05-21T22:39:26.523820Z","shell.execute_reply.started":"2024-05-21T22:39:26.518592Z","shell.execute_reply":"2024-05-21T22:39:26.522954Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:57:12.053140Z","iopub.execute_input":"2024-05-21T22:57:12.053533Z","iopub.status.idle":"2024-05-21T22:57:12.058883Z","shell.execute_reply.started":"2024-05-21T22:57:12.053495Z","shell.execute_reply":"2024-05-21T22:57:12.057679Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Number of epochs\nnum_epochs = 10\nbest_acc = 0.0\nbest_model_wts = model.state_dict()\n\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()  # Set model to evaluate mode\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data with progress bar\n        with tqdm(total=len(dataloaders[phase]), desc=f'{phase} Phase', unit='batch') as pbar:\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.float().view(-1, 1).to(device)  # Reshape labels for binary classification\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.sigmoid(outputs) > 0.5\n                    loss = criterion(outputs, labels)\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n                # Update progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=running_loss / (pbar.n * inputs.size(0)),\n                                 accuracy=running_corrects.double() / (pbar.n * inputs.size(0)))\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Deep copy the model\n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = model.state_dict()\n\n    print()\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\nprint('Best val Acc: {:4f}'.format(best_acc))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T22:57:20.102832Z","iopub.execute_input":"2024-05-21T22:57:20.103199Z","iopub.status.idle":"2024-05-21T23:10:01.774511Z","shell.execute_reply.started":"2024-05-21T22:57:20.103172Z","shell.execute_reply":"2024-05-21T23:10:01.773176Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [01:00<00:00,  1.30s/batch, accuracy=tensor(1.0356, device='cuda:0', dtype=torch.float64), loss=0.267]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2338 Acc: 0.9086\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:26<00:00,  1.68s/batch, accuracy=tensor(1.5295, device='cuda:0', dtype=torch.float64), loss=0.103] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0660 Acc: 0.9789\n\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.24s/batch, accuracy=tensor(1.0798, device='cuda:0', dtype=torch.float64), loss=0.164]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1435 Acc: 0.9473\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:17<00:00,  1.07s/batch, accuracy=tensor(1.5105, device='cuda:0', dtype=torch.float64), loss=0.145] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0931 Acc: 0.9667\n\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.24s/batch, accuracy=tensor(1.0922, device='cuda:0', dtype=torch.float64), loss=0.127]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1118 Acc: 0.9582\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.03batch/s, accuracy=tensor(1.5020, device='cuda:0', dtype=torch.float64), loss=0.181]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.1161 Acc: 0.9613\n\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.25s/batch, accuracy=tensor(1.0943, device='cuda:0', dtype=torch.float64), loss=0.124]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1089 Acc: 0.9601\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.04batch/s, accuracy=tensor(1.5406, device='cuda:0', dtype=torch.float64), loss=0.0656]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0420 Acc: 0.9860\n\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.24s/batch, accuracy=tensor(1.0970, device='cuda:0', dtype=torch.float64), loss=0.112] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0986 Acc: 0.9624\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.01batch/s, accuracy=tensor(1.4518, device='cuda:0', dtype=torch.float64), loss=0.345]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.2210 Acc: 0.9291\n\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.25s/batch, accuracy=tensor(1.1035, device='cuda:0', dtype=torch.float64), loss=0.0981]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0861 Acc: 0.9682\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.03batch/s, accuracy=tensor(1.4510, device='cuda:0', dtype=torch.float64), loss=0.38] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.2432 Acc: 0.9286\n\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:59<00:00,  1.26s/batch, accuracy=tensor(1.1055, device='cuda:0', dtype=torch.float64), loss=0.0944]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0828 Acc: 0.9699\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.04batch/s, accuracy=tensor(1.5328, device='cuda:0', dtype=torch.float64), loss=0.0908]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0581 Acc: 0.9810\n\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.25s/batch, accuracy=tensor(1.1082, device='cuda:0', dtype=torch.float64), loss=0.0846]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0743 Acc: 0.9723\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.01batch/s, accuracy=tensor(1.5084, device='cuda:0', dtype=torch.float64), loss=0.17] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.1090 Acc: 0.9654\n\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [00:58<00:00,  1.25s/batch, accuracy=tensor(1.1094, device='cuda:0', dtype=torch.float64), loss=0.0848]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0744 Acc: 0.9733\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.04batch/s, accuracy=tensor(1.5404, device='cuda:0', dtype=torch.float64), loss=0.0646]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0413 Acc: 0.9859\n\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 47/47 [01:02<00:00,  1.33s/batch, accuracy=tensor(1.1116, device='cuda:0', dtype=torch.float64), loss=0.0786]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0690 Acc: 0.9752\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 16/16 [00:15<00:00,  1.03batch/s, accuracy=tensor(1.5371, device='cuda:0', dtype=torch.float64), loss=0.074] ","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0474 Acc: 0.9838\n\nBest val Acc: 0.986000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nrunning_loss = 0.0\nrunning_corrects = 0\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\ntest_loss = running_loss / len(image_datasets['test'])\ntest_acc = running_corrects.double() / len(image_datasets['test'])\n\nprint(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:10:54.371499Z","iopub.execute_input":"2024-05-21T23:10:54.371899Z","iopub.status.idle":"2024-05-21T23:11:25.480266Z","shell.execute_reply.started":"2024-05-21T23:10:54.371868Z","shell.execute_reply":"2024-05-21T23:11:25.478997Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test Loss: 0.0474 Acc: 0.9823\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 512\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:11:29.934163Z","iopub.execute_input":"2024-05-21T23:11:29.934967Z","iopub.status.idle":"2024-05-21T23:11:32.902514Z","shell.execute_reply.started":"2024-05-21T23:11:29.934913Z","shell.execute_reply":"2024-05-21T23:11:32.901615Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:11:36.926687Z","iopub.execute_input":"2024-05-21T23:11:36.927098Z","iopub.status.idle":"2024-05-21T23:11:36.936755Z","shell.execute_reply.started":"2024-05-21T23:11:36.927068Z","shell.execute_reply":"2024-05-21T23:11:36.935795Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"BinaryCNN(\n  (features): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=50176, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    results.append(test_accuracy.item())\n    losses.append(test_loss)\n\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:11:40.142095Z","iopub.execute_input":"2024-05-21T23:11:40.142860Z","iopub.status.idle":"2024-05-21T23:13:57.799342Z","shell.execute_reply.started":"2024-05-21T23:11:40.142830Z","shell.execute_reply":"2024-05-21T23:13:57.798199Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 0.8286 Acc: 0.7342\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 0.9904 Acc: 0.6811\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 0.7850 Acc: 0.7273\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 6.8563 Acc: 0.1759\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 7.1050 Acc: 0.2898\n\nFinal Results:\nFaceMorpher: 0.7342\nMIPGAN_I: 0.6811\nMIPGAN_II: 0.7273\nOpenCV: 0.1759\nWebmorph: 0.2898\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import roc_curve\n\ndef calculate_metrics(true_labels, predictions, fixed_bpcer=None, fixed_apcer=None):\n    \"\"\"Calculate APCER, BPCER, EER, and their corresponding thresholds.\"\"\"\n    # Convert true_labels and predictions to PyTorch tensors\n    true_labels = torch.tensor(true_labels)\n    predictions = torch.tensor(predictions)\n    \n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Calculate APCER and its threshold at fixed BPCER\n    if fixed_bpcer is not None:\n        fpr_target = fixed_bpcer\n        closest_fpr_index = torch.argmin(torch.abs(torch.tensor(fpr) - fpr_target))\n        apcer = 1 - tpr[closest_fpr_index]\n        apcer_threshold = thresholds[closest_fpr_index]\n    else:\n        apcer = apcer_threshold = None\n    \n    # Calculate BPCER and its threshold at fixed APCER\n    if fixed_apcer is not None:\n        tpr_target = 1 - fixed_apcer\n        closest_tpr_index = torch.argmin(torch.abs(torch.tensor(tpr) - tpr_target))\n        bpcer = fpr[closest_tpr_index]\n        bpcer_threshold = thresholds[closest_tpr_index]\n    else:\n        bpcer = bpcer_threshold = None\n    \n    # Calculate EER and its threshold\n    frr = 1 - tpr\n    eer_index = torch.argmin(torch.abs(torch.tensor(fpr) - torch.tensor(frr)))\n    eer = fpr[eer_index]\n    eer_threshold = thresholds[eer_index]\n    \n    return {\n        \"APCER\": apcer,\n#         \"APCER Threshold\": apcer_threshold,\n        \"BPCER\": bpcer,\n#         \"BPCER Threshold\": bpcer_threshold,\n        \"EER\": eer,\n#         \"EER Threshold\": eer_threshold\n    }\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        metrics = calculate_metrics(true_labels, predictions, fixed_bpcer=fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            **metrics\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        metrics = calculate_metrics(true_labels, predictions, fixed_apcer=fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            **metrics\n        }\n        all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:29:35.974352Z","iopub.execute_input":"2024-05-21T23:29:35.974780Z","iopub.status.idle":"2024-05-21T23:31:20.322240Z","shell.execute_reply.started":"2024-05-21T23:29:35.974743Z","shell.execute_reply":"2024-05-21T23:31:20.321001Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER     BPCER       EER Fixed APCER\n0   FaceMorpher        1.0%  0.092000       NaN  0.014706         NaN\n1   FaceMorpher       10.0%  0.004000       NaN  0.014706         NaN\n2   FaceMorpher       20.0%  0.001000       NaN  0.014706         NaN\n3   FaceMorpher         NaN       NaN  0.044118  0.014706        1.0%\n4   FaceMorpher         NaN       NaN  0.004902  0.014706       10.0%\n5   FaceMorpher         NaN       NaN  0.000000  0.014706       20.0%\n6      MIPGAN_I        1.0%  0.113000       NaN  0.024510         NaN\n7      MIPGAN_I       10.0%  0.003000       NaN  0.024510         NaN\n8      MIPGAN_I       20.0%  0.003000       NaN  0.024510         NaN\n9      MIPGAN_I         NaN       NaN  0.044118  0.024510        1.0%\n10     MIPGAN_I         NaN       NaN  0.004902  0.024510       10.0%\n11     MIPGAN_I         NaN       NaN  0.000000  0.024510       20.0%\n12    MIPGAN_II        1.0%  0.080080       NaN  0.019608         NaN\n13    MIPGAN_II       10.0%  0.003003       NaN  0.019608         NaN\n14    MIPGAN_II       20.0%  0.003003       NaN  0.019608         NaN\n15    MIPGAN_II         NaN       NaN  0.044118  0.019608        1.0%\n16    MIPGAN_II         NaN       NaN  0.000000  0.019608       10.0%\n17    MIPGAN_II         NaN       NaN  0.000000  0.019608       20.0%\n18       OpenCV        1.0%  0.957317       NaN  0.122549         NaN\n19       OpenCV       10.0%  0.155488       NaN  0.122549         NaN\n20       OpenCV       20.0%  0.030488       NaN  0.122549         NaN\n21       OpenCV         NaN       NaN  0.401961  0.122549        1.0%\n22       OpenCV         NaN       NaN  0.137255  0.122549       10.0%\n23       OpenCV         NaN       NaN  0.068627  0.122549       20.0%\n24     Webmorph        1.0%  0.974000       NaN  0.156863         NaN\n25     Webmorph       10.0%  0.284000       NaN  0.156863         NaN\n26     Webmorph       20.0%  0.086000       NaN  0.156863         NaN\n27     Webmorph         NaN       NaN  0.455882  0.156863        1.0%\n28     Webmorph         NaN       NaN  0.181373  0.156863       10.0%\n29     Webmorph         NaN       NaN  0.132353  0.156863       20.0%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the DataFrame to a CSV file\ndf_results.to_csv('metrics_results.csv', index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import roc_curve\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": apcer\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": bpcer\n        }\n        all_results.append(result)\n\n    # Calculate EER\n    eer = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T23:35:21.263870Z","iopub.execute_input":"2024-05-21T23:35:21.264331Z","iopub.status.idle":"2024-05-21T23:37:04.753938Z","shell.execute_reply.started":"2024-05-21T23:35:21.264290Z","shell.execute_reply":"2024-05-21T23:37:04.752620Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER Fixed APCER     BPCER       EER\n0   FaceMorpher        1.0%  0.092000         NaN       NaN       NaN\n1   FaceMorpher       10.0%  0.004000         NaN       NaN       NaN\n2   FaceMorpher       20.0%  0.001000         NaN       NaN       NaN\n3   FaceMorpher         NaN       NaN        1.0%  0.044118       NaN\n4   FaceMorpher         NaN       NaN       10.0%  0.004902       NaN\n5   FaceMorpher         NaN       NaN       20.0%  0.000000       NaN\n6   FaceMorpher         NaN       NaN         NaN       NaN  0.014706\n7      MIPGAN_I        1.0%  0.113000         NaN       NaN       NaN\n8      MIPGAN_I       10.0%  0.003000         NaN       NaN       NaN\n9      MIPGAN_I       20.0%  0.003000         NaN       NaN       NaN\n10     MIPGAN_I         NaN       NaN        1.0%  0.044118       NaN\n11     MIPGAN_I         NaN       NaN       10.0%  0.004902       NaN\n12     MIPGAN_I         NaN       NaN       20.0%  0.000000       NaN\n13     MIPGAN_I         NaN       NaN         NaN       NaN  0.024510\n14    MIPGAN_II        1.0%  0.080080         NaN       NaN       NaN\n15    MIPGAN_II       10.0%  0.003003         NaN       NaN       NaN\n16    MIPGAN_II       20.0%  0.003003         NaN       NaN       NaN\n17    MIPGAN_II         NaN       NaN        1.0%  0.044118       NaN\n18    MIPGAN_II         NaN       NaN       10.0%  0.000000       NaN\n19    MIPGAN_II         NaN       NaN       20.0%  0.000000       NaN\n20    MIPGAN_II         NaN       NaN         NaN       NaN  0.019608\n21       OpenCV        1.0%  0.957317         NaN       NaN       NaN\n22       OpenCV       10.0%  0.155488         NaN       NaN       NaN\n23       OpenCV       20.0%  0.030488         NaN       NaN       NaN\n24       OpenCV         NaN       NaN        1.0%  0.401961       NaN\n25       OpenCV         NaN       NaN       10.0%  0.137255       NaN\n26       OpenCV         NaN       NaN       20.0%  0.068627       NaN\n27       OpenCV         NaN       NaN         NaN       NaN  0.122549\n28     Webmorph        1.0%  0.974000         NaN       NaN       NaN\n29     Webmorph       10.0%  0.284000         NaN       NaN       NaN\n30     Webmorph       20.0%  0.086000         NaN       NaN       NaN\n31     Webmorph         NaN       NaN        1.0%  0.455882       NaN\n32     Webmorph         NaN       NaN       10.0%  0.181373       NaN\n33     Webmorph         NaN       NaN       20.0%  0.132353       NaN\n34     Webmorph         NaN       NaN         NaN       NaN  0.156863\n","output_type":"stream"}]}]}