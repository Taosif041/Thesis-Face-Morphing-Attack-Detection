{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493},{"sourceId":8469777,"sourceType":"datasetVersion","datasetId":5050179}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport warnings\nimport time\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T00:15:37.465611Z","iopub.execute_input":"2024-05-21T00:15:37.466373Z","iopub.status.idle":"2024-05-21T00:15:49.642070Z","shell.execute_reply.started":"2024-05-21T00:15:37.466339Z","shell.execute_reply":"2024-05-21T00:15:49.641319Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-21 00:15:39.144210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-21 00:15:39.144303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-21 00:15:39.277665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_data_generator(data_dir, batch_size):\n    datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.1,\n        brightness_range=[0.5, 1.5],\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    generator = datagen.flow_from_directory(\n        directory=data_dir,\n        target_size=(224, 224),  # Resize images to 224x224 to match the input size of the model\n        batch_size=batch_size,\n        class_mode='binary'  # Binary labels\n    )\n    return generator\n\n# Create generators\nbatch_size = 128\ntrain_generator = create_data_generator('/kaggle/input/morph-splitted/train', batch_size)\nval_generator = create_data_generator('/kaggle/input/morph-splitted/val', batch_size)\ntest_generator = create_data_generator('/kaggle/input/morph-splitted/test', batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:15:49.643542Z","iopub.execute_input":"2024-05-21T00:15:49.644020Z","iopub.status.idle":"2024-05-21T00:16:26.853275Z","shell.execute_reply.started":"2024-05-21T00:15:49.643996Z","shell.execute_reply":"2024-05-21T00:16:26.852521Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 24000 images belonging to 2 classes.\nFound 8000 images belonging to 2 classes.\nFound 8000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.Sequential([\n    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n     \n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid', dtype='float32')  # Ensure the output layer is in float32\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:16:26.864528Z","iopub.execute_input":"2024-05-21T00:16:26.864918Z","iopub.status.idle":"2024-05-21T00:16:27.592267Z","shell.execute_reply.started":"2024-05-21T00:16:26.864894Z","shell.execute_reply":"2024-05-21T00:16:27.591395Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m788544\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m788544\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m788,545\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">788544</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">788544</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,545</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m790,593\u001b[0m (3.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">790,593</span> (3.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m790,465\u001b[0m (3.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">790,465</span> (3.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 3\nbatch_size = 128\nhistory = model.fit(train_generator, epochs=epochs, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:16:27.593484Z","iopub.execute_input":"2024-05-21T00:16:27.593783Z","iopub.status.idle":"2024-05-21T00:48:51.139777Z","shell.execute_reply.started":"2024-05-21T00:16:27.593759Z","shell.execute_reply":"2024-05-21T00:48:51.138795Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m  1/188\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:16\u001b[0m 34s/step - accuracy: 0.4297 - loss: 0.9111","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716250628.154130     129 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 4s/step - accuracy: 0.8590 - loss: 3.0610 - val_accuracy: 0.6344 - val_loss: 0.7421\nEpoch 2/3\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 3s/step - accuracy: 0.9683 - loss: 0.1003 - val_accuracy: 0.9646 - val_loss: 0.1378\nEpoch 3/3\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 3s/step - accuracy: 0.9732 - loss: 0.0915 - val_accuracy: 0.7769 - val_loss: 0.4844\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:48:51.141198Z","iopub.execute_input":"2024-05-21T00:48:51.141872Z","iopub.status.idle":"2024-05-21T00:52:12.848336Z","shell.execute_reply.started":"2024-05-21T00:48:51.141836Z","shell.execute_reply":"2024-05-21T00:52:12.847415Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.7789 - loss: 0.4801\nTest accuracy: 0.7758749723434448\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate predictions\npredictions = model.predict(test_generator)\n\n# Convert predictions to binary labels\npredicted_labels = (predictions > 0.5).astype(int)\n\n# Get true labels\ntrue_labels = test_generator.classes\n\n# Generate classification report\nreport = classification_report(true_labels, predicted_labels)\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:52:12.849391Z","iopub.execute_input":"2024-05-21T00:52:12.849689Z","iopub.status.idle":"2024-05-21T00:54:41.844289Z","shell.execute_reply.started":"2024-05-21T00:52:12.849658Z","shell.execute_reply":"2024-05-21T00:54:41.843055Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step\n              precision    recall  f1-score   support\n\n           0       0.63      0.85      0.72      5000\n           1       0.39      0.16      0.22      3000\n\n    accuracy                           0.59      8000\n   macro avg       0.51      0.51      0.47      8000\nweighted avg       0.54      0.59      0.54      8000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"fm_generator = create_data_generator('/kaggle/input/mad-benchmark/FaceMorpher', batch_size)\nmg1_generator = create_data_generator('/kaggle/input/mad-benchmark/MIPGAN_I', batch_size)\nmg2_generator = create_data_generator('/kaggle/input/mad-benchmark/MIPGAN_II', batch_size)\noc_generator = create_data_generator('/kaggle/input/mad-benchmark/OpenCV', batch_size)\nwm_generator = create_data_generator('/kaggle/input/mad-benchmark/Webmorph', batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:54:41.845413Z","iopub.execute_input":"2024-05-21T00:54:41.845711Z","iopub.status.idle":"2024-05-21T00:54:43.938709Z","shell.execute_reply.started":"2024-05-21T00:54:41.845685Z","shell.execute_reply":"2024-05-21T00:54:43.937933Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 1204 images belonging to 2 classes.\nFound 1204 images belonging to 2 classes.\nFound 1203 images belonging to 2 classes.\nFound 1188 images belonging to 2 classes.\nFound 704 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(wm_generator)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:54:43.948211Z","iopub.execute_input":"2024-05-21T00:54:43.948492Z","iopub.status.idle":"2024-05-21T00:55:19.073212Z","shell.execute_reply.started":"2024-05-21T00:54:43.948468Z","shell.execute_reply":"2024-05-21T00:55:19.072371Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.3020 - loss: 3.1712\n","output_type":"stream"}]},{"cell_type":"code","source":"datasets = [fm_generator, mg1_generator, mg2_generator, oc_generator,wm_generator]\nresults = []\nfor i in datasets:\n    test_loss, test_accuracy = model.evaluate(i, batch_size=16)\n    results.append(test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T00:55:19.074571Z","iopub.execute_input":"2024-05-21T00:55:19.074895Z","iopub.status.idle":"2024-05-21T01:00:21.914612Z","shell.execute_reply.started":"2024-05-21T00:55:19.074870Z","shell.execute_reply":"2024-05-21T01:00:21.913602Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - accuracy: 0.1814 - loss: 4.8413\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8s/step - accuracy: 0.1853 - loss: 2.4774\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8s/step - accuracy: 0.1929 - loss: 2.3490\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - accuracy: 0.1716 - loss: 3.4034\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.2912 - loss: 3.3278\n","output_type":"stream"}]},{"cell_type":"code","source":"names = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor i,j in zip(names, results):\n    print(i, \": \", j)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:00:21.916222Z","iopub.execute_input":"2024-05-21T01:00:21.916869Z","iopub.status.idle":"2024-05-21T01:00:21.922456Z","shell.execute_reply.started":"2024-05-21T01:00:21.916834Z","shell.execute_reply":"2024-05-21T01:00:21.921560Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"FaceMorpher :  0.18189369142055511\nMIPGAN_I :  0.1901993304491043\nMIPGAN_II :  0.19617623090744019\nOpenCV :  0.1734006702899933\nWebmorph :  0.28977271914482117\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **apcer_at_fixed_bpcer**","metadata":{}},{"cell_type":"code","source":"def calculate_apcer_at_fixed_bpcer(fpr, tpr, thresholds, fixed_bpcer):\n    \"\"\"Calculate the APCER at a fixed BPCER.\"\"\"\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    corresponding_apcer = 1 - tpr[closest_fpr_index]\n    corresponding_threshold = thresholds[closest_fpr_index]\n    return corresponding_apcer, corresponding_threshold","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:00:21.923737Z","iopub.execute_input":"2024-05-21T01:00:21.924025Z","iopub.status.idle":"2024-05-21T01:00:21.932846Z","shell.execute_reply.started":"2024-05-21T01:00:21.923995Z","shell.execute_reply":"2024-05-21T01:00:21.932129Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# def calculate_apcer_at_fixed_bpcer(fpr, tpr, thresholds, fixed_bpcer):\n#     \"\"\"Calculate the APCER at a fixed BPCER.\"\"\"\n#     tpr_target = 1 - fixed_bpcer\n#     closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n#     corresponding_apcer = fpr[closest_tpr_index]\n#     corresponding_threshold = thresholds[closest_tpr_index]\n#     return corresponding_apcer, corresponding_threshold\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:00:21.933743Z","iopub.execute_input":"2024-05-21T01:00:21.933970Z","iopub.status.idle":"2024-05-21T01:00:21.950823Z","shell.execute_reply.started":"2024-05-21T01:00:21.933951Z","shell.execute_reply":"2024-05-21T01:00:21.950049Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"datasets = [ fm_generator, mg1_generator, mg2_generator, oc_generator,wm_generator]\nnames = [ \"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]  # Define fixed BPCER values\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    # Evaluate the model\n    test_loss, test_accuracy = model.evaluate(dataset, steps=dataset.samples // dataset.batch_size)\n    \n    # Predictions and true labels\n    predictions = model.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # ROC curve metrics\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Calculate APCER for each BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        apcer, threshold = calculate_apcer_at_fixed_bpcer(fpr, tpr, thresholds, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": f\"{apcer:.3f}\",\n            \"Threshold\": f\"{threshold:.3f}\",\n            \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n        }\n        all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:00:21.951961Z","iopub.execute_input":"2024-05-21T01:00:21.952263Z","iopub.status.idle":"2024-05-21T01:11:36.185522Z","shell.execute_reply.started":"2024-05-21T01:00:21.952240Z","shell.execute_reply":"2024-05-21T01:11:36.184561Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.1837 - loss: 4.7958\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.1880 - loss: 2.4147\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.1951 - loss: 2.3785\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 11s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 10s/step - accuracy: 0.1823 - loss: 3.3998\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8s/step - accuracy: 0.3001 - loss: 3.2040\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step\n        Dataset Fixed BPCER  APCER Threshold Test Accuracy\n0   FaceMorpher        1.0%  0.996     0.683          0.18\n1   FaceMorpher       10.0%  0.900     0.123          0.18\n2   FaceMorpher       20.0%  0.789     0.033          0.18\n3      MIPGAN_I        1.0%  0.987     0.522          0.18\n4      MIPGAN_I       10.0%  0.917     0.265          0.18\n5      MIPGAN_I       20.0%  0.820     0.156          0.18\n6     MIPGAN_II        1.0%  0.983     0.575          0.20\n7     MIPGAN_II       10.0%  0.917     0.316          0.20\n8     MIPGAN_II       20.0%  0.805     0.175          0.20\n9        OpenCV        1.0%  0.991     0.389          0.18\n10       OpenCV       10.0%  0.931     0.138          0.18\n11       OpenCV       20.0%  0.842     0.073          0.18\n12     Webmorph        1.0%  0.990     0.290          0.29\n13     Webmorph       10.0%  0.898     0.076          0.29\n14     Webmorph       20.0%  0.760     0.034          0.29\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **bpcer_at_fixed_apcer**","metadata":{}},{"cell_type":"code","source":"def calculate_bpcer_at_fixed_apcer(fpr, tpr, thresholds, fixed_apcer):\n    \"\"\"Calculate the BPCER at a fixed APCER.\"\"\"\n    closest_index = np.argmin(np.abs(fpr - fixed_apcer))\n    corresponding_bpcer = 1 - tpr[closest_index]\n    corresponding_threshold = thresholds[closest_index]\n    return corresponding_bpcer, corresponding_threshold\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:11:36.186782Z","iopub.execute_input":"2024-05-21T01:11:36.187543Z","iopub.status.idle":"2024-05-21T01:11:36.192742Z","shell.execute_reply.started":"2024-05-21T01:11:36.187506Z","shell.execute_reply":"2024-05-21T01:11:36.191754Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define datasets, model predictions, and fixed APCER values\ndatasets = [ fm_generator, mg1_generator, mg2_generator, oc_generator,wm_generator]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    # Evaluate the model\n    test_loss, test_accuracy = model.evaluate(dataset, steps=dataset.samples // dataset.batch_size)\n    \n    # Predictions and true labels\n    predictions = model.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # ROC curve metrics\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Calculate BPCER for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        bpcer, threshold = calculate_bpcer_at_fixed_apcer(fpr, tpr, thresholds, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": f\"{bpcer:.3f}\",\n            \"Threshold\": f\"{threshold:.3f}\",\n            \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n        }\n        all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:11:36.194252Z","iopub.execute_input":"2024-05-21T01:11:36.194600Z","iopub.status.idle":"2024-05-21T01:21:34.639908Z","shell.execute_reply.started":"2024-05-21T01:11:36.194567Z","shell.execute_reply":"2024-05-21T01:21:34.638968Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 8s/step - accuracy: 0.1957 - loss: 4.6174\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 12s/step - accuracy: 0.1878 - loss: 2.3891\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.1996 - loss: 2.3193\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3s/step - accuracy: 0.1682 - loss: 3.4621\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.2984 - loss: 3.2771\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step\n        Dataset Fixed APCER  BPCER Threshold Test Accuracy\n0   FaceMorpher        1.0%  0.981     0.481          0.18\n1   FaceMorpher       10.0%  0.876     0.127          0.18\n2   FaceMorpher       20.0%  0.753     0.037          0.18\n3      MIPGAN_I        1.0%  0.982     0.571          0.19\n4      MIPGAN_I       10.0%  0.898     0.264          0.19\n5      MIPGAN_I       20.0%  0.841     0.178          0.19\n6     MIPGAN_II        1.0%  0.996     0.619          0.20\n7     MIPGAN_II       10.0%  0.890     0.264          0.20\n8     MIPGAN_II       20.0%  0.803     0.173          0.20\n9        OpenCV        1.0%  0.992     0.365          0.18\n10       OpenCV       10.0%  0.852     0.089          0.18\n11       OpenCV       20.0%  0.748     0.047          0.18\n12     Webmorph        1.0%  0.982     0.335          0.30\n13     Webmorph       10.0%  0.896     0.076          0.30\n14     Webmorph       20.0%  0.804     0.038          0.30\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.save('model.h5')  # Saves the entire model to a single HDF5 file.","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:21:34.641674Z","iopub.execute_input":"2024-05-21T01:21:34.641960Z","iopub.status.idle":"2024-05-21T01:21:34.646010Z","shell.execute_reply.started":"2024-05-21T01:21:34.641934Z","shell.execute_reply":"2024-05-21T01:21:34.644986Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom tensorflow.keras.backend import clear_session\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate the Equal Error Rate (EER) and the corresponding threshold.\"\"\"\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Compute FRR (False Rejection Rate)\n    frr = 1 - tpr\n    \n    # Find the EER (Equal Error Rate)\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    eer_threshold = thresholds[eer_index]\n    \n    return eer, eer_threshold\n\n# Define datasets and model predictions\ndatasets = [fm_generator, mg1_generator, mg2_generator, oc_generator, wm_generator]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n#     clear_session()  # Clear session to free up memory\n\n    # Evaluate the model\n    test_loss, test_accuracy = model.evaluate(dataset, steps=dataset.samples // dataset.batch_size)\n    \n    # Predictions and true labels\n    predictions = model.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # Calculate EER\n    eer, eer_threshold = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": f\"{eer:.3f}\",\n        \"Threshold\": f\"{eer_threshold:.3f}\",\n        \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n    }\n    all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:21:34.647439Z","iopub.execute_input":"2024-05-21T01:21:34.647911Z","iopub.status.idle":"2024-05-21T01:30:07.745326Z","shell.execute_reply.started":"2024-05-21T01:21:34.647878Z","shell.execute_reply":"2024-05-21T01:30:07.744398Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.1664 - loss: 4.9988\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.1905 - loss: 2.5083\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.1981 - loss: 2.2891\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - accuracy: 0.1777 - loss: 3.4952\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.2808 - loss: 3.4381\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step\n       Dataset    EER Threshold Test Accuracy\n0  FaceMorpher  0.500     0.001          0.19\n1     MIPGAN_I  0.505     0.044          0.19\n2    MIPGAN_II  0.515     0.050          0.21\n3       OpenCV  0.495     0.015          0.18\n4     Webmorph  0.485     0.006          0.29\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Full code in a cell","metadata":{}},{"cell_type":"code","source":"'''\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.lay\ners import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport warnings\nwarnings.filterwarnings('ignore')\ndef create_data_generator(data_dir, batch_size):\n    datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.1,\n        brightness_range=[0.5, 1.5],\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    generator = datagen.flow_from_directory(\n        directory=data_dir,\n        target_size=(224, 224),  # Resize images to 224x224 to match the input size of the model\n        batch_size=batch_size,\n        class_mode='binary'  # Binary labels\n    )\n    return generator\n\n# Create generators\nbatch_size = 32\ntrain_generator = create_data_generator('/kaggle/input/morph-splitted/train', batch_size)\nval_generator = create_data_generator('/kaggle/input/morph-splitted/val', batch_size)\ntest_generator = create_data_generator('/kaggle/input/morph-splitted/test', batch_size)\n\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, 3, activation='relu', input_shape=(224, 224, 3)),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 1024\nhistory = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n'''\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:30:07.746750Z","iopub.execute_input":"2024-05-21T01:30:07.747357Z","iopub.status.idle":"2024-05-21T01:30:07.756102Z","shell.execute_reply.started":"2024-05-21T01:30:07.747321Z","shell.execute_reply":"2024-05-21T01:30:07.755180Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"\"\\nimport tensorflow as tf\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\\nfrom tensorflow.keras.applications import Xception\\nfrom tensorflow.keras.lay\\ners import Dense, GlobalAveragePooling2D\\nfrom tensorflow.keras.models import Model\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.metrics import roc_curve\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nimport warnings\\nwarnings.filterwarnings('ignore')\\ndef create_data_generator(data_dir, batch_size):\\n    datagen = ImageDataGenerator(\\n        rescale=1./255,\\n        rotation_range=20,\\n        width_shift_range=0.2,\\n        height_shift_range=0.2,\\n        shear_range=0.15,\\n        zoom_range=0.1,\\n        brightness_range=[0.5, 1.5],\\n        horizontal_flip=True,\\n        fill_mode='nearest'\\n    )\\n    generator = datagen.flow_from_directory(\\n        directory=data_dir,\\n        target_size=(224, 224),  # Resize images to 224x224 to match the input size of the model\\n        batch_size=batch_size,\\n        class_mode='binary'  # Binary labels\\n    )\\n    return generator\\n\\n# Create generators\\nbatch_size = 32\\ntrain_generator = create_data_generator('/kaggle/input/morph-splitted/train', batch_size)\\nval_generator = create_data_generator('/kaggle/input/morph-splitted/val', batch_size)\\ntest_generator = create_data_generator('/kaggle/input/morph-splitted/test', batch_size)\\n\\n\\nmodel = tf.keras.models.Sequential([\\n    tf.keras.layers.Conv2D(64, 3, activation='relu', input_shape=(224, 224, 3)),\\n    tf.keras.layers.MaxPooling2D(),\\n    tf.keras.layers.Flatten(),\\n    tf.keras.layers.Dense(1, activation='sigmoid')\\n])\\nmodel.compile(optimizer='adam',\\n              loss='binary_crossentropy',\\n              metrics=['accuracy'])\\n\\nepochs = 10\\nbatch_size = 1024\\nhistory = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\\n\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}