{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T10:44:42.595595Z","iopub.execute_input":"2024-05-22T10:44:42.596303Z","iopub.status.idle":"2024-05-22T10:44:43.703766Z","shell.execute_reply.started":"2024-05-22T10:44:42.596266Z","shell.execute_reply":"2024-05-22T10:44:43.702878Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define transforms for data augmentation and normalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:45:22.062019Z","iopub.execute_input":"2024-05-22T10:45:22.062462Z","iopub.status.idle":"2024-05-22T10:45:22.071744Z","shell.execute_reply.started":"2024-05-22T10:45:22.062426Z","shell.execute_reply":"2024-05-22T10:45:22.070574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:45:24.143607Z","iopub.execute_input":"2024-05-22T10:45:24.143974Z","iopub.status.idle":"2024-05-22T10:45:24.148914Z","shell.execute_reply.started":"2024-05-22T10:45:24.143939Z","shell.execute_reply":"2024-05-22T10:45:24.147687Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:03.255445Z","iopub.execute_input":"2024-05-22T10:47:03.256578Z","iopub.status.idle":"2024-05-22T10:47:10.763760Z","shell.execute_reply.started":"2024-05-22T10:47:03.256540Z","shell.execute_reply":"2024-05-22T10:47:10.762529Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False, num_workers=4)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:48.109705Z","iopub.execute_input":"2024-05-22T10:47:48.110125Z","iopub.status.idle":"2024-05-22T10:47:48.116179Z","shell.execute_reply.started":"2024-05-22T10:47:48.110094Z","shell.execute_reply":"2024-05-22T10:47:48.115195Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Define the VGG19 model for binary classification\nclass BinaryVGG19(nn.Module):\n    def __init__(self):\n        super(BinaryVGG19, self).__init__()\n        self.features = models.vgg19(pretrained=True).features\n        for param in self.features.parameters():\n            param.requires_grad = False\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 1)  # Output layer with 1 neuron for binary classification\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Instantiate the model\nmodel = BinaryVGG19()\n\n# Define device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.001)  # Only train the classifier\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:50.134944Z","iopub.execute_input":"2024-05-22T10:47:50.135858Z","iopub.status.idle":"2024-05-22T10:47:57.492567Z","shell.execute_reply.started":"2024-05-22T10:47:50.135822Z","shell.execute_reply":"2024-05-22T10:47:57.491534Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n100%|██████████| 548M/548M [00:03<00:00, 159MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 10\nbest_acc = 0.0\nbest_model_wts = model.state_dict()\n\n# Define dataset sizes\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:48:03.227502Z","iopub.execute_input":"2024-05-22T10:48:03.227879Z","iopub.status.idle":"2024-05-22T10:48:03.234503Z","shell.execute_reply.started":"2024-05-22T10:48:03.227848Z","shell.execute_reply":"2024-05-22T10:48:03.233419Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()  # Set model to evaluate mode\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data with progress bar\n        with tqdm(total=len(dataloaders[phase]), desc=f'{phase} Phase', unit='batch') as pbar:\n            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.sigmoid(outputs).round()\n                    loss = criterion(outputs, labels.unsqueeze(1).float())\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.unsqueeze(1))\n\n                # Update progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * inputs.size(0)),\n                                 accuracy=running_corrects.double() / ((pbar.n + 1) * inputs.size(0)))\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Deep copy the model\n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = model.state_dict()\n\n    print()\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\nprint('Best val Acc: {:4f}'.format(best_acc))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:48:06.744747Z","iopub.execute_input":"2024-05-22T10:48:06.745154Z","iopub.status.idle":"2024-05-22T11:08:40.787669Z","shell.execute_reply.started":"2024-05-22T10:48:06.745114Z","shell.execute_reply":"2024-05-22T11:08:40.786342Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:38<00:00,  7.62batch/s, accuracy=tensor(0.9273, device='cuda:0', dtype=torch.float64), loss=0.218]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2182 Acc: 0.9285\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  8.96batch/s, accuracy=tensor(0.9868, device='cuda:0', dtype=torch.float64), loss=0.0259] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0260 Acc: 0.9908\n\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.82batch/s, accuracy=tensor(0.9537, device='cuda:0', dtype=torch.float64), loss=0.13] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1297 Acc: 0.9550\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.15batch/s, accuracy=tensor(0.9507, device='cuda:0', dtype=torch.float64), loss=0.137]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.1373 Acc: 0.9545\n\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.82batch/s, accuracy=tensor(0.9564, device='cuda:0', dtype=torch.float64), loss=0.124]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1245 Acc: 0.9577\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.18batch/s, accuracy=tensor(0.9744, device='cuda:0', dtype=torch.float64), loss=0.0754] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0757 Acc: 0.9783\n\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.82batch/s, accuracy=tensor(0.9560, device='cuda:0', dtype=torch.float64), loss=0.142]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1424 Acc: 0.9573\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.19batch/s, accuracy=tensor(0.9699, device='cuda:0', dtype=torch.float64), loss=0.0605] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0608 Acc: 0.9738\n\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.83batch/s, accuracy=tensor(0.9622, device='cuda:0', dtype=torch.float64), loss=0.109]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1089 Acc: 0.9635\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.21batch/s, accuracy=tensor(0.9543, device='cuda:0', dtype=torch.float64), loss=0.126]   \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.1262 Acc: 0.9581\n\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.83batch/s, accuracy=tensor(0.9660, device='cuda:0', dtype=torch.float64), loss=0.103] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1028 Acc: 0.9673\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.23batch/s, accuracy=tensor(0.9834, device='cuda:0', dtype=torch.float64), loss=0.0302] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0304 Acc: 0.9874\n\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.82batch/s, accuracy=tensor(0.9629, device='cuda:0', dtype=torch.float64), loss=0.114] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1138 Acc: 0.9642\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.20batch/s, accuracy=tensor(0.9573, device='cuda:0', dtype=torch.float64), loss=0.0897]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0901 Acc: 0.9611\n\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.83batch/s, accuracy=tensor(0.9659, device='cuda:0', dtype=torch.float64), loss=0.102] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1024 Acc: 0.9672\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.19batch/s, accuracy=tensor(0.9668, device='cuda:0', dtype=torch.float64), loss=0.0859] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0862 Acc: 0.9706\n\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.83batch/s, accuracy=tensor(0.9683, device='cuda:0', dtype=torch.float64), loss=0.0976]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0977 Acc: 0.9696\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.20batch/s, accuracy=tensor(0.9633, device='cuda:0', dtype=torch.float64), loss=0.0927]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0931 Acc: 0.9671\n\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 750/750 [01:35<00:00,  7.82batch/s, accuracy=tensor(0.9676, device='cuda:0', dtype=torch.float64), loss=0.106] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1066 Acc: 0.9689\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 250/250 [00:27<00:00,  9.19batch/s, accuracy=tensor(0.9894, device='cuda:0', dtype=torch.float64), loss=0.0186] ","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0187 Acc: 0.9934\n\nBest val Acc: 0.993375\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nrunning_loss = 0.0\nrunning_corrects = 0\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\ntest_loss = running_loss / len(image_datasets['test'])\ntest_acc = running_corrects.double() / len(image_datasets['test'])\n\nprint(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:09:34.609526Z","iopub.execute_input":"2024-05-22T11:09:34.610209Z","iopub.status.idle":"2024-05-22T11:10:00.591345Z","shell.execute_reply.started":"2024-05-22T11:09:34.610174Z","shell.execute_reply":"2024-05-22T11:10:00.590072Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Test Loss: 0.0191 Acc: 0.9929\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 512\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:21:21.933079Z","iopub.execute_input":"2024-05-22T11:21:21.933484Z","iopub.status.idle":"2024-05-22T11:21:26.811913Z","shell.execute_reply.started":"2024-05-22T11:21:21.933451Z","shell.execute_reply":"2024-05-22T11:21:26.810992Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:21:31.365318Z","iopub.execute_input":"2024-05-22T11:21:31.365953Z","iopub.status.idle":"2024-05-22T11:21:31.375481Z","shell.execute_reply.started":"2024-05-22T11:21:31.365920Z","shell.execute_reply":"2024-05-22T11:21:31.374612Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"BinaryVGG19(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): ReLU(inplace=True)\n    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (33): ReLU(inplace=True)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): ReLU(inplace=True)\n    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    results.append(test_accuracy.item())\n    losses.append(test_loss)\n\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:21:34.395822Z","iopub.execute_input":"2024-05-22T11:21:34.396212Z","iopub.status.idle":"2024-05-22T11:23:51.041778Z","shell.execute_reply.started":"2024-05-22T11:21:34.396180Z","shell.execute_reply":"2024-05-22T11:23:51.040448Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 6.1213 Acc: 0.3729\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 26.2404 Acc: 0.1694\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 27.2281 Acc: 0.1696\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 12.1749 Acc: 0.1726\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                  ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 12.0803 Acc: 0.2912\n\nFinal Results:\nFaceMorpher: 0.3729\nMIPGAN_I: 0.1694\nMIPGAN_II: 0.1696\nOpenCV: 0.1726\nWebmorph: 0.2912\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()  # Ensure the model is in evaluation mode\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        with torch.no_grad():  # Disable gradient computation\n            predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": apcer\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": bpcer\n        }\n        all_results.append(result)\n\n    # Calculate EER\n    eer = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:25:19.830612Z","iopub.execute_input":"2024-05-22T11:25:19.831087Z","iopub.status.idle":"2024-05-22T11:27:07.912625Z","shell.execute_reply.started":"2024-05-22T11:25:19.831049Z","shell.execute_reply":"2024-05-22T11:27:07.911438Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER Fixed APCER     BPCER       EER\n0   FaceMorpher        1.0%  0.240000         NaN       NaN       NaN\n1   FaceMorpher       10.0%  0.131000         NaN       NaN       NaN\n2   FaceMorpher       20.0%  0.083000         NaN       NaN       NaN\n3   FaceMorpher         NaN       NaN        1.0%  0.735294       NaN\n4   FaceMorpher         NaN       NaN       10.0%  0.166667       NaN\n5   FaceMorpher         NaN       NaN       20.0%  0.009804       NaN\n6   FaceMorpher         NaN       NaN         NaN       NaN  0.112745\n7      MIPGAN_I        1.0%  0.988000         NaN       NaN       NaN\n8      MIPGAN_I       10.0%  0.974000         NaN       NaN       NaN\n9      MIPGAN_I       20.0%  0.945000         NaN       NaN       NaN\n10     MIPGAN_I         NaN       NaN        1.0%  0.995098       NaN\n11     MIPGAN_I         NaN       NaN       10.0%  0.980392       NaN\n12     MIPGAN_I         NaN       NaN       20.0%  0.950980       NaN\n13     MIPGAN_I         NaN       NaN         NaN       NaN  0.720588\n14    MIPGAN_II        1.0%  0.994995         NaN       NaN       NaN\n15    MIPGAN_II       10.0%  0.980981         NaN       NaN       NaN\n16    MIPGAN_II       20.0%  0.969970         NaN       NaN       NaN\n17    MIPGAN_II         NaN       NaN        1.0%  0.995098       NaN\n18    MIPGAN_II         NaN       NaN       10.0%  0.985294       NaN\n19    MIPGAN_II         NaN       NaN       20.0%  0.960784       NaN\n20    MIPGAN_II         NaN       NaN         NaN       NaN  0.730392\n21       OpenCV        1.0%  0.636179         NaN       NaN       NaN\n22       OpenCV       10.0%  0.418699         NaN       NaN       NaN\n23       OpenCV       20.0%  0.276423         NaN       NaN       NaN\n24       OpenCV         NaN       NaN        1.0%  0.857843       NaN\n25       OpenCV         NaN       NaN       10.0%  0.553922       NaN\n26       OpenCV         NaN       NaN       20.0%  0.338235       NaN\n27       OpenCV         NaN       NaN         NaN       NaN  0.254902\n28     Webmorph        1.0%  0.726000         NaN       NaN       NaN\n29     Webmorph       10.0%  0.544000         NaN       NaN       NaN\n30     Webmorph       20.0%  0.408000         NaN       NaN       NaN\n31     Webmorph         NaN       NaN        1.0%  0.946078       NaN\n32     Webmorph         NaN       NaN       10.0%  0.700980       NaN\n33     Webmorph         NaN       NaN       20.0%  0.509804       NaN\n34     Webmorph         NaN       NaN         NaN       NaN  0.323529\n","output_type":"stream"}]}]}