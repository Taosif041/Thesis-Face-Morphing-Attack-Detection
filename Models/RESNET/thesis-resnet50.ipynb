{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T13:07:30.117319Z","iopub.execute_input":"2024-05-21T13:07:30.118310Z","iopub.status.idle":"2024-05-21T13:07:42.408694Z","shell.execute_reply.started":"2024-05-21T13:07:30.118270Z","shell.execute_reply":"2024-05-21T13:07:42.407534Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-21 13:07:31.971994: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-21 13:07:31.972093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-21 13:07:32.104470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_data_generator(data_dir, batch_size):\n    datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.1,\n        brightness_range=[0.5, 1.5],\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    generator = datagen.flow_from_directory(\n        directory=data_dir,\n        target_size=(224, 224),  # Resize images to 224x224 to match the input size of the model\n        batch_size=batch_size,\n        class_mode='binary'  # Binary labels\n    )\n    return generator\n\n# Create generators\nbatch_size = 512\ntrain_generator = create_data_generator('/kaggle/input/morph-splitted/train', batch_size)\nval_generator = create_data_generator('/kaggle/input/morph-splitted/val', batch_size)\ntest_generator = create_data_generator('/kaggle/input/morph-splitted/test', batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:07:42.410947Z","iopub.execute_input":"2024-05-21T13:07:42.412098Z","iopub.status.idle":"2024-05-21T13:08:13.270598Z","shell.execute_reply.started":"2024-05-21T13:07:42.412057Z","shell.execute_reply":"2024-05-21T13:08:13.269775Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 24000 images belonging to 2 classes.\nFound 8000 images belonging to 2 classes.\nFound 8000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **ResNet50**","metadata":{}},{"cell_type":"code","source":"# Load pre-trained ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Adding custom layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation='relu')(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel_ResNet50 = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile model\nmodel_ResNet50.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:08:13.271633Z","iopub.execute_input":"2024-05-21T13:08:13.271895Z","iopub.status.idle":"2024-05-21T13:08:18.542059Z","shell.execute_reply.started":"2024-05-21T13:08:13.271872Z","shell.execute_reply":"2024-05-21T13:08:18.541237Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit the model\nbatch_size = 512\nepochs = 10\nhistory = model_ResNet50.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=val_generator,\n    validation_steps=val_generator.samples // val_generator.batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:08:18.544675Z","iopub.execute_input":"2024-05-21T13:08:18.545327Z","iopub.status.idle":"2024-05-21T13:57:07.292623Z","shell.execute_reply.started":"2024-05-21T13:08:18.545294Z","shell.execute_reply":"2024-05-21T13:57:07.291806Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  2/750\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 54ms/step - accuracy: 0.6172 - loss: 0.6581   ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716296918.543616     126 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716296918.593948     126 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m749/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.6439 - loss: 0.5987","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716297418.384009     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 884ms/step - accuracy: 0.6439 - loss: 0.5986 - val_accuracy: 0.6659 - val_loss: 0.5812\nEpoch 2/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 3/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 723ms/step - accuracy: 0.6973 - loss: 0.5333 - val_accuracy: 0.7212 - val_loss: 0.5097\nEpoch 4/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 5/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 753ms/step - accuracy: 0.7329 - loss: 0.4989 - val_accuracy: 0.7725 - val_loss: 0.4544\nEpoch 6/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 7/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 767ms/step - accuracy: 0.7622 - loss: 0.4597 - val_accuracy: 0.6679 - val_loss: 0.6017\nEpoch 8/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 9/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 732ms/step - accuracy: 0.7732 - loss: 0.4494 - val_accuracy: 0.8453 - val_loss: 0.3919\nEpoch 10/10\n\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on test data\ntest_loss, test_accuracy = model_ResNet50.evaluate(test_generator)\nprint(f\"Test accuracy: {test_accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:57:07.294045Z","iopub.execute_input":"2024-05-21T13:57:07.294846Z","iopub.status.idle":"2024-05-21T14:00:54.087216Z","shell.execute_reply.started":"2024-05-21T13:57:07.294811Z","shell.execute_reply":"2024-05-21T14:00:54.086268Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 902ms/step - accuracy: 0.8453 - loss: 0.3957\nTest accuracy: 0.8418750166893005\n","output_type":"stream"}]},{"cell_type":"code","source":"fm_generator = create_data_generator('/kaggle/input/mad-benchmark/FaceMorpher', batch_size)\nmg1_generator = create_data_generator('/kaggle/input/mad-benchmark/MIPGAN_I', batch_size)\nmg2_generator = create_data_generator('/kaggle/input/mad-benchmark/MIPGAN_II', batch_size)\noc_generator = create_data_generator('/kaggle/input/mad-benchmark/OpenCV', batch_size)\nwm_generator = create_data_generator('/kaggle/input/mad-benchmark/Webmorph', batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:00:54.088320Z","iopub.execute_input":"2024-05-21T14:00:54.088587Z","iopub.status.idle":"2024-05-21T14:00:57.338930Z","shell.execute_reply.started":"2024-05-21T14:00:54.088564Z","shell.execute_reply":"2024-05-21T14:00:57.338015Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 1204 images belonging to 2 classes.\nFound 1204 images belonging to 2 classes.\nFound 1203 images belonging to 2 classes.\nFound 1188 images belonging to 2 classes.\nFound 704 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"datasets = [fm_generator, mg1_generator, mg2_generator, oc_generator,wm_generator]\nresults = []\nlosses = []\nfor i in datasets:\n    test_loss, test_accuracy = model_ResNet50.evaluate(i)\n    results.append(test_accuracy)\n    losses.append(test_loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:00:57.340234Z","iopub.execute_input":"2024-05-21T14:00:57.340548Z","iopub.status.idle":"2024-05-21T14:09:15.846417Z","shell.execute_reply.started":"2024-05-21T14:00:57.340522Z","shell.execute_reply":"2024-05-21T14:09:15.845406Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9s/step - accuracy: 0.4587 - loss: 1.3323 \n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300141.492812     126 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 18s/step - accuracy: 0.3530 - loss: 1.5515\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 25s/step - accuracy: 0.3767 - loss: 1.4309\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300419.414279     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15s/step - accuracy: 0.2664 - loss: 2.0968\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300495.862246     124 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19s/step - accuracy: 0.3209 - loss: 2.1240\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300555.664577     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"code","source":"names = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor i,j in zip(names, results):\n    print(i, \": \", j)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:09:37.025503Z","iopub.execute_input":"2024-05-21T14:09:37.026504Z","iopub.status.idle":"2024-05-21T14:09:37.031898Z","shell.execute_reply.started":"2024-05-21T14:09:37.026468Z","shell.execute_reply":"2024-05-21T14:09:37.030829Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"FaceMorpher :  0.45847177505493164\nMIPGAN_I :  0.35548171401023865\nMIPGAN_II :  0.36907729506492615\nOpenCV :  0.2651515007019043\nWebmorph :  0.33096590638160706\n","output_type":"stream"}]},{"cell_type":"code","source":"# from tensorflow.keras.models import load_model\n# model.save(os.path.join('models','model_ResNet50.h5'))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:09:45.205014Z","iopub.execute_input":"2024-05-21T14:09:45.205365Z","iopub.status.idle":"2024-05-21T14:09:45.209462Z","shell.execute_reply.started":"2024-05-21T14:09:45.205339Z","shell.execute_reply":"2024-05-21T14:09:45.208393Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# new_model = load_model('models/model_ResNet50.h5')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:09:50.230708Z","iopub.execute_input":"2024-05-21T14:09:50.231112Z","iopub.status.idle":"2024-05-21T14:09:50.235456Z","shell.execute_reply.started":"2024-05-21T14:09:50.231081Z","shell.execute_reply":"2024-05-21T14:09:50.234358Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### **apcer_at_fixed_bpcer**","metadata":{}},{"cell_type":"code","source":"def calculate_apcer_at_fixed_bpcer(fpr, tpr, thresholds, fixed_bpcer):\n    \"\"\"Calculate the APCER at a fixed BPCER.\"\"\"\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    corresponding_apcer = 1 - tpr[closest_fpr_index]\n    corresponding_threshold = thresholds[closest_fpr_index]\n    return corresponding_apcer, corresponding_threshold","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:10:06.407466Z","iopub.execute_input":"2024-05-21T14:10:06.408285Z","iopub.status.idle":"2024-05-21T14:10:06.413311Z","shell.execute_reply.started":"2024-05-21T14:10:06.408255Z","shell.execute_reply":"2024-05-21T14:10:06.412269Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"datasets = [fm_generator, mg1_generator, mg2_generator, oc_generator, wm_generator]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]  # Define fixed BPCER values\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    # Evaluate the model and get results\n    index = datasets.index(dataset)  # Index of the current dataset\n    test_loss = losses[index]\n    test_accuracy = results[index]\n    \n    # Predictions and true labels\n    predictions = model_ResNet50.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # ROC curve metrics\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Calculate APCER for each BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        apcer, threshold = calculate_apcer_at_fixed_bpcer(fpr, tpr, thresholds, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": f\"{apcer:.3f}\",\n            \"Threshold\": f\"{threshold:.3f}\",\n            \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n        }\n        all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:10:09.032678Z","iopub.execute_input":"2024-05-21T14:10:09.033055Z","iopub.status.idle":"2024-05-21T14:16:16.850344Z","shell.execute_reply.started":"2024-05-21T14:10:09.033026Z","shell.execute_reply":"2024-05-21T14:16:16.849314Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7s/step\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300652.606113     126 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 17s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 18s/step\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300871.664141     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9s/step\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300930.609891     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8s/step\n        Dataset Fixed BPCER  APCER Threshold Test Accuracy\n0   FaceMorpher        1.0%  0.990     0.786          0.46\n1   FaceMorpher       10.0%  0.896     0.635          0.46\n2   FaceMorpher       20.0%  0.769     0.560          0.46\n3      MIPGAN_I        1.0%  0.996     0.749          0.36\n4      MIPGAN_I       10.0%  0.869     0.559          0.36\n5      MIPGAN_I       20.0%  0.752     0.474          0.36\n6     MIPGAN_II        1.0%  0.979     0.694          0.37\n7     MIPGAN_II       10.0%  0.891     0.581          0.37\n8     MIPGAN_II       20.0%  0.821     0.532          0.37\n9        OpenCV        1.0%  0.997     0.696          0.27\n10       OpenCV       10.0%  0.862     0.464          0.27\n11       OpenCV       20.0%  0.748     0.344          0.27\n12     Webmorph        1.0%  0.986     0.609          0.33\n13     Webmorph       10.0%  0.868     0.417          0.33\n14     Webmorph       20.0%  0.792     0.312          0.33\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716300976.651692     123 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **bpcer_at_fixed_apcer**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\n\ndef calculate_bpcer_at_fixed_apcer(fpr, tpr, thresholds, fixed_apcer):\n    \"\"\"Calculate the BPCER at a fixed APCER.\"\"\"\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    corresponding_bpcer = fpr[closest_tpr_index]\n    corresponding_threshold = thresholds[closest_tpr_index]\n    return corresponding_bpcer, corresponding_threshold\n\n# Define datasets, model predictions, and fixed APCER values\ndatasets = [fm_generator, mg1_generator, mg2_generator, oc_generator, wm_generator]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    # Evaluate the model\n    test_loss, test_accuracy = model_ResNet50.evaluate(dataset, steps=dataset.samples // dataset.batch_size)\n    \n    # Predictions and true labels\n    predictions = model_ResNet50.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # ROC curve metrics\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Calculate BPCER for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        bpcer, threshold = calculate_bpcer_at_fixed_apcer(fpr, tpr, thresholds, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": f\"{bpcer:.3f}\",\n#             \"Threshold\": f\"{threshold:.3f}\",\n            \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n        }\n        all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:38:49.006256Z","iopub.execute_input":"2024-05-21T14:38:49.007169Z","iopub.status.idle":"2024-05-21T14:51:02.622007Z","shell.execute_reply.started":"2024-05-21T14:38:49.007135Z","shell.execute_reply":"2024-05-21T14:51:02.620948Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9s/step - accuracy: 0.4740 - loss: 1.3218\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25s/step - accuracy: 0.3555 - loss: 1.4889\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 18s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26s/step - accuracy: 0.4023 - loss: 1.3736\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 18s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - accuracy: 0.2415 - loss: 2.0967\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.3379 - loss: 1.9626\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step\n        Dataset Fixed APCER  BPCER Test Accuracy\n0   FaceMorpher        1.0%  0.995          0.47\n1   FaceMorpher       10.0%  0.887          0.47\n2   FaceMorpher       20.0%  0.848          0.47\n3      MIPGAN_I        1.0%  0.995          0.35\n4      MIPGAN_I       10.0%  0.853          0.35\n5      MIPGAN_I       20.0%  0.804          0.35\n6     MIPGAN_II        1.0%  0.990          0.41\n7     MIPGAN_II       10.0%  0.868          0.41\n8     MIPGAN_II       20.0%  0.755          0.41\n9        OpenCV        1.0%  0.995          0.25\n10       OpenCV       10.0%  0.951          0.25\n11       OpenCV       20.0%  0.828          0.25\n12     Webmorph        1.0%  0.985          0.34\n13     Webmorph       10.0%  0.887          0.34\n14     Webmorph       20.0%  0.814          0.34\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **EER**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom tensorflow.keras.backend import clear_session\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate the Equal Error Rate (EER) and the corresponding threshold.\"\"\"\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    \n    # Compute FRR (False Rejection Rate)\n    frr = 1 - tpr\n    \n    # Find the EER (Equal Error Rate)\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    eer_threshold = thresholds[eer_index]\n    \n    return eer, eer_threshold\n\n# Define datasets and model predictions\ndatasets = [fm_generator, mg1_generator, mg2_generator, oc_generator, wm_generator]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nall_results = []\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n#     clear_session()  # Clear session to free up memory\n\n    # Evaluate the model\n    test_loss, test_accuracy = model_ResNet50.evaluate(dataset, steps=dataset.samples // dataset.batch_size)\n    \n    # Predictions and true labels\n    predictions = model_ResNet50.predict(dataset)\n    true_labels = dataset.classes\n    if predictions.ndim > 1 and predictions.shape[1] > 1:\n        predictions = predictions[:, 1]\n\n    # Calculate EER\n    eer, eer_threshold = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": f\"{eer:.3f}\",\n        \"Threshold\": f\"{eer_threshold:.3f}\",\n        \"Test Accuracy\": f\"{test_accuracy:.2f}\"\n    }\n    all_results.append(result)\n\n# Create DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:25:04.867778Z","iopub.execute_input":"2024-05-21T14:25:04.868509Z","iopub.status.idle":"2024-05-21T14:37:40.627913Z","shell.execute_reply.started":"2024-05-21T14:25:04.868479Z","shell.execute_reply":"2024-05-21T14:37:40.626900Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9s/step - accuracy: 0.4785 - loss: 1.2803\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25s/step - accuracy: 0.3730 - loss: 1.4713\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 17s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25s/step - accuracy: 0.3796 - loss: 1.4686\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 17s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13s/step - accuracy: 0.2637 - loss: 2.1007\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.3711 - loss: 1.8904\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step\n       Dataset    EER Threshold Test Accuracy\n0  FaceMorpher  0.495     0.273          0.47\n1     MIPGAN_I  0.505     0.247          0.38\n2    MIPGAN_II  0.490     0.245          0.38\n3       OpenCV  0.505     0.109          0.27\n4     Webmorph  0.480     0.050          0.37\n","output_type":"stream"}]}]}