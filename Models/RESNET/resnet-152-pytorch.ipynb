{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve\nimport pandas as pd\n# from apex import amp  # for mixed precision training\nfrom torchvision import models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T15:37:20.645161Z","iopub.execute_input":"2024-05-22T15:37:20.645946Z","iopub.status.idle":"2024-05-22T15:37:20.651371Z","shell.execute_reply.started":"2024-05-22T15:37:20.645898Z","shell.execute_reply":"2024-05-22T15:37:20.650398Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n\n# Define transforms for data augmentation and normalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(degrees=30),  # Random rotation up to 30 degrees\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation up to 10% of image size\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n        transforms.GaussianBlur(kernel_size=3),  # Gaussian blur with kernel size 3\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:20.653001Z","iopub.execute_input":"2024-05-22T15:37:20.653330Z","iopub.status.idle":"2024-05-22T15:37:20.670782Z","shell.execute_reply.started":"2024-05-22T15:37:20.653297Z","shell.execute_reply":"2024-05-22T15:37:20.669770Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:20.672465Z","iopub.execute_input":"2024-05-22T15:37:20.672811Z","iopub.status.idle":"2024-05-22T15:37:20.681962Z","shell.execute_reply.started":"2024-05-22T15:37:20.672782Z","shell.execute_reply":"2024-05-22T15:37:20.681096Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:20.683114Z","iopub.execute_input":"2024-05-22T15:37:20.683533Z","iopub.status.idle":"2024-05-22T15:37:50.025465Z","shell.execute_reply.started":"2024-05-22T15:37:20.683499Z","shell.execute_reply":"2024-05-22T15:37:50.024496Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=16, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=16, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=16, shuffle=False, num_workers=4)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:50.027934Z","iopub.execute_input":"2024-05-22T15:37:50.028622Z","iopub.status.idle":"2024-05-22T15:37:50.033904Z","shell.execute_reply.started":"2024-05-22T15:37:50.028587Z","shell.execute_reply":"2024-05-22T15:37:50.033096Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:50.035163Z","iopub.execute_input":"2024-05-22T15:37:50.035423Z","iopub.status.idle":"2024-05-22T15:37:50.068176Z","shell.execute_reply.started":"2024-05-22T15:37:50.035400Z","shell.execute_reply":"2024-05-22T15:37:50.067295Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\n# Define ResNet-152 model for binary classification\nclass ResNet152Binary(nn.Module):\n    def __init__(self):\n        super(ResNet152Binary, self).__init__()\n        self.model = models.resnet152(pretrained=True)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, 1)  # Output layer with 1 neuron for binary classification\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Initialize the model\nmodel = ResNet152Binary().to(device)\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\noptimizer = optim.Adam(model.parameters(), lr=0.0001)  # Only train the classifier\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:50.069289Z","iopub.execute_input":"2024-05-22T15:37:50.069551Z","iopub.status.idle":"2024-05-22T15:37:53.317325Z","shell.execute_reply.started":"2024-05-22T15:37:50.069528Z","shell.execute_reply":"2024-05-22T15:37:53.316472Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n100%|██████████| 230M/230M [00:01<00:00, 162MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 10\nbest_model_wts = model.state_dict()\nbest_acc = 0.0\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:53.318453Z","iopub.execute_input":"2024-05-22T15:37:53.318723Z","iopub.status.idle":"2024-05-22T15:37:53.328889Z","shell.execute_reply.started":"2024-05-22T15:37:53.318699Z","shell.execute_reply":"2024-05-22T15:37:53.328161Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()  # Set model to evaluate mode\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data with progress bar\n        with tqdm(total=len(dataloaders[phase]), desc=f'{phase} Phase', unit='batch') as pbar:\n            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.sigmoid(outputs).round()\n                    # Convert labels to match the output size of the model\n                    labels = labels.unsqueeze(1).float()  # Convert to shape (batch_size, 1)\n#                     print('Output shape:', outputs.shape)\n#                     print('Target shape:', labels.shape)\n                    loss = criterion(outputs, labels)\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels)\n\n                # Update progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * inputs.size(0)),\n                                 accuracy=running_corrects.double() / ((pbar.n + 1) * inputs.size(0)))\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Deep copy the model\n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = model.state_dict()\n\n    print()\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\nprint('Best val Acc: {:4f}'.format(best_acc))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:37:53.330171Z","iopub.execute_input":"2024-05-22T15:37:53.330427Z","iopub.status.idle":"2024-05-22T16:38:52.314920Z","shell.execute_reply.started":"2024-05-22T15:37:53.330405Z","shell.execute_reply":"2024-05-22T16:38:52.313802Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:31<00:00,  4.53batch/s, accuracy=tensor(0.9626, device='cuda:0', dtype=torch.float64), loss=0.0957]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0958 Acc: 0.9632\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:36<00:00, 13.59batch/s, accuracy=tensor(0.9966, device='cuda:0', dtype=torch.float64), loss=0.0152] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0152 Acc: 0.9986\n\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:29<00:00,  4.55batch/s, accuracy=tensor(0.9821, device='cuda:0', dtype=torch.float64), loss=0.0493]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0493 Acc: 0.9828\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 14.16batch/s, accuracy=tensor(0.9837, device='cuda:0', dtype=torch.float64), loss=0.0377]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0378 Acc: 0.9856\n\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:29<00:00,  4.55batch/s, accuracy=tensor(0.9863, device='cuda:0', dtype=torch.float64), loss=0.0356]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0356 Acc: 0.9869\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 14.16batch/s, accuracy=tensor(0.9975, device='cuda:0', dtype=torch.float64), loss=0.00366] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0037 Acc: 0.9995\n\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:29<00:00,  4.56batch/s, accuracy=tensor(0.9862, device='cuda:0', dtype=torch.float64), loss=0.0357]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0358 Acc: 0.9869\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 14.11batch/s, accuracy=tensor(0.9949, device='cuda:0', dtype=torch.float64), loss=0.00837] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0084 Acc: 0.9969\n\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:29<00:00,  4.55batch/s, accuracy=tensor(0.9885, device='cuda:0', dtype=torch.float64), loss=0.0285]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0285 Acc: 0.9891\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 13.98batch/s, accuracy=tensor(0.9954, device='cuda:0', dtype=torch.float64), loss=0.00812] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0081 Acc: 0.9974\n\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:30<00:00,  4.54batch/s, accuracy=tensor(0.9900, device='cuda:0', dtype=torch.float64), loss=0.0276]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0276 Acc: 0.9907\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 13.98batch/s, accuracy=tensor(0.9976, device='cuda:0', dtype=torch.float64), loss=0.0007]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0007 Acc: 0.9996\n\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:30<00:00,  4.54batch/s, accuracy=tensor(0.9901, device='cuda:0', dtype=torch.float64), loss=0.0227]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0227 Acc: 0.9908\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 13.97batch/s, accuracy=tensor(0.9975, device='cuda:0', dtype=torch.float64), loss=0.00249] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0025 Acc: 0.9995\n\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:30<00:00,  4.54batch/s, accuracy=tensor(0.9913, device='cuda:0', dtype=torch.float64), loss=0.0226]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0226 Acc: 0.9920\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 14.01batch/s, accuracy=tensor(0.9978, device='cuda:0', dtype=torch.float64), loss=0.00127] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0013 Acc: 0.9998\n\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:30<00:00,  4.54batch/s, accuracy=tensor(0.9902, device='cuda:0', dtype=torch.float64), loss=0.025] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0250 Acc: 0.9909\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 13.99batch/s, accuracy=tensor(0.9959, device='cuda:0', dtype=torch.float64), loss=0.00547] \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0055 Acc: 0.9979\n\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [05:30<00:00,  4.54batch/s, accuracy=tensor(0.9929, device='cuda:0', dtype=torch.float64), loss=0.0184]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0184 Acc: 0.9936\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:35<00:00, 13.99batch/s, accuracy=tensor(0.9956, device='cuda:0', dtype=torch.float64), loss=0.0072]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0072 Acc: 0.9976\n\nBest val Acc: 0.999750\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nrunning_loss = 0.0\nrunning_corrects = 0\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\ntest_loss = running_loss / len(image_datasets['test'])\ntest_acc = running_corrects.double() / len(image_datasets['test'])\n\nprint(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:38:52.316382Z","iopub.execute_input":"2024-05-22T16:38:52.316697Z","iopub.status.idle":"2024-05-22T16:39:26.986093Z","shell.execute_reply.started":"2024-05-22T16:38:52.316668Z","shell.execute_reply":"2024-05-22T16:39:26.985060Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Test Loss: 0.0068 Acc: 0.9979\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 32\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:39:26.990797Z","iopub.execute_input":"2024-05-22T16:39:26.991094Z","iopub.status.idle":"2024-05-22T16:39:29.319496Z","shell.execute_reply.started":"2024-05-22T16:39:26.991068Z","shell.execute_reply":"2024-05-22T16:39:29.318625Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:39:29.320568Z","iopub.execute_input":"2024-05-22T16:39:29.320845Z","iopub.status.idle":"2024-05-22T16:39:29.338920Z","shell.execute_reply.started":"2024-05-22T16:39:29.320821Z","shell.execute_reply":"2024-05-22T16:39:29.337899Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"ResNet152Binary(\n  (model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (8): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (9): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (10): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (11): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (12): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (13): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (14): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (15): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (16): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (17): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (18): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (19): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (20): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (21): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (22): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (23): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (24): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (25): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (26): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (27): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (28): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (29): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (30): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (31): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (32): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (33): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (34): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (35): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    results.append(test_accuracy.item())\n    losses.append(test_loss)\n\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:39:29.340242Z","iopub.execute_input":"2024-05-22T16:39:29.340542Z","iopub.status.idle":"2024-05-22T16:40:54.187194Z","shell.execute_reply.started":"2024-05-22T16:39:29.340519Z","shell.execute_reply":"2024-05-22T16:40:54.186121Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 3.8489 Acc: 0.2841\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 12.9275 Acc: 0.1694\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 12.5385 Acc: 0.1696\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 8.2922 Acc: 0.1717\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 7.7924 Acc: 0.2898\n\nFinal Results:\nFaceMorpher: 0.2841\nMIPGAN_I: 0.1694\nMIPGAN_II: 0.1696\nOpenCV: 0.1717\nWebmorph: 0.2898\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()  # Ensure the model is in evaluation mode\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        with torch.no_grad():  # Disable gradient computation\n            predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": apcer\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": bpcer\n        }\n        all_results.append(result)\n\n    # Calculate EER\n    eer = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:40:54.188665Z","iopub.execute_input":"2024-05-22T16:40:54.189084Z","iopub.status.idle":"2024-05-22T16:42:05.177271Z","shell.execute_reply.started":"2024-05-22T16:40:54.189055Z","shell.execute_reply":"2024-05-22T16:42:05.176109Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER Fixed APCER     BPCER       EER\n0   FaceMorpher        1.0%  0.159000         NaN       NaN       NaN\n1   FaceMorpher       10.0%  0.019000         NaN       NaN       NaN\n2   FaceMorpher       20.0%  0.011000         NaN       NaN       NaN\n3   FaceMorpher         NaN       NaN        1.0%  0.171569       NaN\n4   FaceMorpher         NaN       NaN       10.0%  0.009804       NaN\n5   FaceMorpher         NaN       NaN       20.0%  0.000000       NaN\n6   FaceMorpher         NaN       NaN         NaN       NaN  0.039216\n7      MIPGAN_I        1.0%  0.970000         NaN       NaN       NaN\n8      MIPGAN_I       10.0%  0.782000         NaN       NaN       NaN\n9      MIPGAN_I       20.0%  0.593000         NaN       NaN       NaN\n10     MIPGAN_I         NaN       NaN        1.0%  0.892157       NaN\n11     MIPGAN_I         NaN       NaN       10.0%  0.720588       NaN\n12     MIPGAN_I         NaN       NaN       20.0%  0.602941       NaN\n13     MIPGAN_I         NaN       NaN         NaN       NaN  0.411765\n14    MIPGAN_II        1.0%  0.972973         NaN       NaN       NaN\n15    MIPGAN_II       10.0%  0.721722         NaN       NaN       NaN\n16    MIPGAN_II       20.0%  0.555556         NaN       NaN       NaN\n17    MIPGAN_II         NaN       NaN        1.0%  0.901961       NaN\n18    MIPGAN_II         NaN       NaN       10.0%  0.686275       NaN\n19    MIPGAN_II         NaN       NaN       20.0%  0.568627       NaN\n20    MIPGAN_II         NaN       NaN         NaN       NaN  0.387255\n21       OpenCV        1.0%  0.711382         NaN       NaN       NaN\n22       OpenCV       10.0%  0.163618         NaN       NaN       NaN\n23       OpenCV       20.0%  0.063008         NaN       NaN       NaN\n24       OpenCV         NaN       NaN        1.0%  0.568627       NaN\n25       OpenCV         NaN       NaN       10.0%  0.147059       NaN\n26       OpenCV         NaN       NaN       20.0%  0.063725       NaN\n27       OpenCV         NaN       NaN         NaN       NaN  0.117647\n28     Webmorph        1.0%  0.806000         NaN       NaN       NaN\n29     Webmorph       10.0%  0.248000         NaN       NaN       NaN\n30     Webmorph       20.0%  0.096000         NaN       NaN       NaN\n31     Webmorph         NaN       NaN        1.0%  0.544118       NaN\n32     Webmorph         NaN       NaN       10.0%  0.191176       NaN\n33     Webmorph         NaN       NaN       20.0%  0.098039       NaN\n34     Webmorph         NaN       NaN         NaN       NaN  0.147059\n","output_type":"stream"}]}]}