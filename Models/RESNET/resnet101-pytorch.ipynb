{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271362,"sourceType":"datasetVersion","datasetId":4910963},{"sourceId":8290075,"sourceType":"datasetVersion","datasetId":4924493}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve\nimport pandas as pd\n# from apex import amp  # for mixed precision training\nfrom torchvision import models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T11:39:53.484968Z","iopub.execute_input":"2024-05-22T11:39:53.485335Z","iopub.status.idle":"2024-05-22T11:40:00.408547Z","shell.execute_reply.started":"2024-05-22T11:39:53.485293Z","shell.execute_reply":"2024-05-22T11:40:00.407785Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Define transforms for data augmentation and normalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:00.410011Z","iopub.execute_input":"2024-05-22T11:40:00.410550Z","iopub.status.idle":"2024-05-22T11:40:00.418090Z","shell.execute_reply.started":"2024-05-22T11:40:00.410522Z","shell.execute_reply":"2024-05-22T11:40:00.417162Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set the paths to your training and validation directories\ntrain_dir = '/kaggle/input/morph-splitted/train'\nval_dir = '/kaggle/input/morph-splitted/val'\ntest_dir = '/kaggle/input/morph-splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:00.419114Z","iopub.execute_input":"2024-05-22T11:40:00.419369Z","iopub.status.idle":"2024-05-22T11:40:00.429818Z","shell.execute_reply.started":"2024-05-22T11:40:00.419346Z","shell.execute_reply":"2024-05-22T11:40:00.429042Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:00.432160Z","iopub.execute_input":"2024-05-22T11:40:00.432747Z","iopub.status.idle":"2024-05-22T11:40:40.143406Z","shell.execute_reply.started":"2024-05-22T11:40:00.432715Z","shell.execute_reply":"2024-05-22T11:40:40.142459Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=16, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=16, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=16, shuffle=False, num_workers=4)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:40.144647Z","iopub.execute_input":"2024-05-22T11:40:40.145030Z","iopub.status.idle":"2024-05-22T11:40:40.151498Z","shell.execute_reply.started":"2024-05-22T11:40:40.144997Z","shell.execute_reply":"2024-05-22T11:40:40.150271Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:40.153111Z","iopub.execute_input":"2024-05-22T11:40:40.153709Z","iopub.status.idle":"2024-05-22T11:40:40.189006Z","shell.execute_reply.started":"2024-05-22T11:40:40.153676Z","shell.execute_reply":"2024-05-22T11:40:40.188070Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define ResNet-101 model for binary classification\nclass ResNet101Binary(nn.Module):\n    def __init__(self):\n        super(ResNet101Binary, self).__init__()\n        self.model = models.resnet101(pretrained=True)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, 1)  # Output layer with 1 neuron for binary classification\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Initialize the model\nmodel = ResNet101Binary().to(device)\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)  # Update optimizer to optimize all parameters of the model\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:43:51.785622Z","iopub.execute_input":"2024-05-22T11:43:51.786060Z","iopub.status.idle":"2024-05-22T11:43:52.855556Z","shell.execute_reply.started":"2024-05-22T11:43:51.786029Z","shell.execute_reply":"2024-05-22T11:43:52.854575Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nbest_model_wts = model.state_dict()\nbest_acc = 0.0\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:43:56.174069Z","iopub.execute_input":"2024-05-22T11:43:56.174424Z","iopub.status.idle":"2024-05-22T11:43:56.184372Z","shell.execute_reply.started":"2024-05-22T11:43:56.174394Z","shell.execute_reply":"2024-05-22T11:43:56.183488Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()  # Set model to evaluate mode\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data with progress bar\n        with tqdm(total=len(dataloaders[phase]), desc=f'{phase} Phase', unit='batch') as pbar:\n            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.sigmoid(outputs).round()\n                    # Convert labels to match the output size of the model\n                    labels = labels.unsqueeze(1).float()  # Convert to shape (batch_size, 1)\n#                     print('Output shape:', outputs.shape)\n#                     print('Target shape:', labels.shape)\n                    loss = criterion(outputs, labels)\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels)\n\n                # Update progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * inputs.size(0)),\n                                 accuracy=running_corrects.double() / ((pbar.n + 1) * inputs.size(0)))\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Deep copy the model\n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = model.state_dict()\n\n    print()\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\nprint('Best val Acc: {:4f}'.format(best_acc))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:44:25.231566Z","iopub.execute_input":"2024-05-22T11:44:25.232452Z","iopub.status.idle":"2024-05-22T12:28:40.289882Z","shell.execute_reply.started":"2024-05-22T11:44:25.232416Z","shell.execute_reply":"2024-05-22T12:28:40.288731Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [04:00<00:00,  6.25batch/s, accuracy=tensor(0.9555, device='cuda:0', dtype=torch.float64), loss=0.115]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1148 Acc: 0.9561\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:27<00:00, 18.45batch/s, accuracy=tensor(0.9844, device='cuda:0', dtype=torch.float64), loss=0.0429]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0430 Acc: 0.9864\n\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:59<00:00,  6.27batch/s, accuracy=tensor(0.9716, device='cuda:0', dtype=torch.float64), loss=0.078] \n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0780 Acc: 0.9723\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.77batch/s, accuracy=tensor(0.9903, device='cuda:0', dtype=torch.float64), loss=0.0288]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0289 Acc: 0.9922\n\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:59<00:00,  6.27batch/s, accuracy=tensor(0.9770, device='cuda:0', dtype=torch.float64), loss=0.0618]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0618 Acc: 0.9777\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.78batch/s, accuracy=tensor(0.9642, device='cuda:0', dtype=torch.float64), loss=0.0935]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0937 Acc: 0.9661\n\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.29batch/s, accuracy=tensor(0.9782, device='cuda:0', dtype=torch.float64), loss=0.0565]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0566 Acc: 0.9789\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.84batch/s, accuracy=tensor(0.9732, device='cuda:0', dtype=torch.float64), loss=0.076]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0761 Acc: 0.9751\n\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.29batch/s, accuracy=tensor(0.9836, device='cuda:0', dtype=torch.float64), loss=0.0448]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0448 Acc: 0.9842\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.83batch/s, accuracy=tensor(0.9923, device='cuda:0', dtype=torch.float64), loss=0.0159]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0160 Acc: 0.9942\n\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.29batch/s, accuracy=tensor(0.9862, device='cuda:0', dtype=torch.float64), loss=0.0379]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0380 Acc: 0.9869\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.85batch/s, accuracy=tensor(0.9712, device='cuda:0', dtype=torch.float64), loss=0.073]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0732 Acc: 0.9731\n\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.28batch/s, accuracy=tensor(0.9866, device='cuda:0', dtype=torch.float64), loss=0.0367]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0367 Acc: 0.9873\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.76batch/s, accuracy=tensor(0.9904, device='cuda:0', dtype=torch.float64), loss=0.0244]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0244 Acc: 0.9924\n\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.28batch/s, accuracy=tensor(0.9888, device='cuda:0', dtype=torch.float64), loss=0.0312]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0312 Acc: 0.9894\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.89batch/s, accuracy=tensor(0.9774, device='cuda:0', dtype=torch.float64), loss=0.054]   \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0541 Acc: 0.9794\n\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.29batch/s, accuracy=tensor(0.9897, device='cuda:0', dtype=torch.float64), loss=0.0286]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0287 Acc: 0.9903\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.86batch/s, accuracy=tensor(0.9923, device='cuda:0', dtype=torch.float64), loss=0.0179]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0180 Acc: 0.9942\n\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"train Phase: 100%|██████████| 1500/1500 [03:58<00:00,  6.29batch/s, accuracy=tensor(0.9911, device='cuda:0', dtype=torch.float64), loss=0.0238]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0238 Acc: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"val Phase: 100%|██████████| 500/500 [00:26<00:00, 18.80batch/s, accuracy=tensor(0.9794, device='cuda:0', dtype=torch.float64), loss=0.0477]  \n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.0478 Acc: 0.9814\n\nBest val Acc: 0.994250\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nrunning_loss = 0.0\nrunning_corrects = 0\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\ntest_loss = running_loss / len(image_datasets['test'])\ntest_acc = running_corrects.double() / len(image_datasets['test'])\n\nprint(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:39:33.429385Z","iopub.execute_input":"2024-05-22T12:39:33.429770Z","iopub.status.idle":"2024-05-22T12:39:59.903202Z","shell.execute_reply.started":"2024-05-22T12:39:33.429731Z","shell.execute_reply":"2024-05-22T12:39:59.902012Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Test Loss: 0.0435 Acc: 0.9824\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Function to create data loaders\ndef create_data_loader(data_dir, transform, batch_size):\n    dataset = datasets.ImageFolder(data_dir, transform)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return data_loader\n\n# Define the transforms for the datasets\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 32\n\n# Create data loaders for each dataset\nfm_loader = create_data_loader('/kaggle/input/mad-benchmark/FaceMorpher', transform, batch_size)\nmg1_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_I', transform, batch_size)\nmg2_loader = create_data_loader('/kaggle/input/mad-benchmark/MIPGAN_II', transform, batch_size)\noc_loader = create_data_loader('/kaggle/input/mad-benchmark/OpenCV', transform, batch_size)\nwm_loader = create_data_loader('/kaggle/input/mad-benchmark/Webmorph', transform, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:41:43.538111Z","iopub.execute_input":"2024-05-22T12:41:43.538473Z","iopub.status.idle":"2024-05-22T12:41:43.760848Z","shell.execute_reply.started":"2024-05-22T12:41:43.538441Z","shell.execute_reply":"2024-05-22T12:41:43.759865Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_loaders = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nresults = []\nlosses = []\n\n# Evaluate the model on each dataset\ncriterion = nn.BCEWithLogitsLoss()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:41:46.750336Z","iopub.execute_input":"2024-05-22T12:41:46.750687Z","iopub.status.idle":"2024-05-22T12:41:46.765961Z","shell.execute_reply.started":"2024-05-22T12:41:46.750657Z","shell.execute_reply":"2024-05-22T12:41:46.765005Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"ResNet101Binary(\n  (model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (8): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (9): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (10): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (11): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (12): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (13): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (14): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (15): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (16): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (17): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (18): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (19): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (20): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (21): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (22): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for loader_idx, data_loader in enumerate(data_loaders):\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n\n    dataset_name = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"][loader_idx]\n    print(f\"Evaluating dataset: {dataset_name}\")\n\n    for inputs, labels in tqdm(data_loader, desc=f\"Processing {dataset_name}\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.float().view(-1, 1).to(device)\n\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs) > 0.5\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n\n    test_loss = running_loss / total_samples\n    test_accuracy = running_corrects.double() / total_samples\n\n    results.append(test_accuracy.item())\n    losses.append(test_loss)\n\n    print(f\"{dataset_name} - Loss: {test_loss:.4f} Acc: {test_accuracy:.4f}\")\n\n# Print the final results\nprint(\"\\nFinal Results:\")\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfor name, accuracy in zip(names, results):\n    print(f\"{name}: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:41:52.463965Z","iopub.execute_input":"2024-05-22T12:41:52.464749Z","iopub.status.idle":"2024-05-22T12:43:10.170490Z","shell.execute_reply.started":"2024-05-22T12:41:52.464718Z","shell.execute_reply":"2024-05-22T12:43:10.169495Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Evaluating dataset: FaceMorpher\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"FaceMorpher - Loss: 0.6723 Acc: 0.7807\nEvaluating dataset: MIPGAN_I\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_I - Loss: 0.5266 Acc: 0.8007\nEvaluating dataset: MIPGAN_II\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MIPGAN_II - Loss: 0.5023 Acc: 0.8238\nEvaluating dataset: OpenCV\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"OpenCV - Loss: 4.5039 Acc: 0.1860\nEvaluating dataset: Webmorph\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"Webmorph - Loss: 5.3649 Acc: 0.2912\n\nFinal Results:\nFaceMorpher: 0.7807\nMIPGAN_I: 0.8007\nMIPGAN_II: 0.8238\nOpenCV: 0.1860\nWebmorph: 0.2912\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Evaluation Metrics**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\n\ndef calculate_apcer(true_labels, predictions, fixed_bpcer):\n    \"\"\"Calculate APCER at a fixed BPCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    fpr_target = fixed_bpcer\n    closest_fpr_index = np.argmin(np.abs(fpr - fpr_target))\n    apcer = 1 - tpr[closest_fpr_index]\n    return apcer\n\ndef calculate_bpcer(true_labels, predictions, fixed_apcer):\n    \"\"\"Calculate BPCER at a fixed APCER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    tpr_target = 1 - fixed_apcer\n    closest_tpr_index = np.argmin(np.abs(tpr - tpr_target))\n    bpcer = fpr[closest_tpr_index]\n    return bpcer\n\ndef calculate_eer(true_labels, predictions):\n    \"\"\"Calculate EER.\"\"\"\n    fpr, tpr, thresholds = roc_curve(true_labels, predictions, pos_label=1)\n    frr = 1 - tpr\n    eer_index = np.argmin(np.abs(fpr - frr))\n    eer = fpr[eer_index]\n    return eer\n\n# Define datasets and model predictions\ndatasets = [fm_loader, mg1_loader, mg2_loader, oc_loader, wm_loader]\nnames = [\"FaceMorpher\", \"MIPGAN_I\", \"MIPGAN_II\", \"OpenCV\", \"Webmorph\"]\nfixed_bpcer_values = [0.01, 0.1, 0.2]\nfixed_apcer_values = [0.01, 0.1, 0.2]\nall_results = []\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()  # Ensure the model is in evaluation mode\n\n# Iterate over each dataset\nfor dataset, name in zip(datasets, names):\n    print(f\"Evaluating model on dataset: {name}\")\n    \n    # Predictions and true labels\n    all_predictions = []\n    all_true_labels = []\n    for inputs, labels in dataset:\n        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU\n        with torch.no_grad():  # Disable gradient computation\n            predictions = model(inputs)\n        all_predictions.append(predictions.detach().cpu().numpy())\n        all_true_labels.append(labels.cpu().numpy())\n    predictions = np.concatenate(all_predictions)\n    true_labels = np.concatenate(all_true_labels)\n\n    # Calculate metrics for each fixed BPCER\n    for fixed_bpcer in fixed_bpcer_values:\n        print(f\"Calculating metrics for fixed BPCER: {fixed_bpcer}\")\n        apcer = calculate_apcer(true_labels, predictions, fixed_bpcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed BPCER\": f\"{fixed_bpcer * 100:.1f}%\",\n            \"APCER\": apcer\n        }\n        all_results.append(result)\n    \n    # Calculate metrics for each fixed APCER\n    for fixed_apcer in fixed_apcer_values:\n        print(f\"Calculating metrics for fixed APCER: {fixed_apcer}\")\n        bpcer = calculate_bpcer(true_labels, predictions, fixed_apcer)\n        result = {\n            \"Dataset\": name,\n            \"Fixed APCER\": f\"{fixed_apcer * 100:.1f}%\",\n            \"BPCER\": bpcer\n        }\n        all_results.append(result)\n\n    # Calculate EER\n    eer = calculate_eer(true_labels, predictions)\n    result = {\n        \"Dataset\": name,\n        \"EER\": eer\n    }\n    all_results.append(result)\n\n# Convert the results to a Pandas DataFrame\ndf_results = pd.DataFrame(all_results)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:43:49.693717Z","iopub.execute_input":"2024-05-22T12:43:49.694365Z","iopub.status.idle":"2024-05-22T12:44:57.799121Z","shell.execute_reply.started":"2024-05-22T12:43:49.694313Z","shell.execute_reply":"2024-05-22T12:44:57.798063Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Evaluating model on dataset: FaceMorpher\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_I\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: MIPGAN_II\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: OpenCV\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\nEvaluating model on dataset: Webmorph\nCalculating metrics for fixed BPCER: 0.01\nCalculating metrics for fixed BPCER: 0.1\nCalculating metrics for fixed BPCER: 0.2\nCalculating metrics for fixed APCER: 0.01\nCalculating metrics for fixed APCER: 0.1\nCalculating metrics for fixed APCER: 0.2\n        Dataset Fixed BPCER     APCER Fixed APCER     BPCER       EER\n0   FaceMorpher        1.0%  0.176000         NaN       NaN       NaN\n1   FaceMorpher       10.0%  0.023000         NaN       NaN       NaN\n2   FaceMorpher       20.0%  0.005000         NaN       NaN       NaN\n3   FaceMorpher         NaN       NaN        1.0%  0.161765       NaN\n4   FaceMorpher         NaN       NaN       10.0%  0.009804       NaN\n5   FaceMorpher         NaN       NaN       20.0%  0.000000       NaN\n6   FaceMorpher         NaN       NaN         NaN       NaN  0.039216\n7      MIPGAN_I        1.0%  0.149000         NaN       NaN       NaN\n8      MIPGAN_I       10.0%  0.009000         NaN       NaN       NaN\n9      MIPGAN_I       20.0%  0.004000         NaN       NaN       NaN\n10     MIPGAN_I         NaN       NaN        1.0%  0.063725       NaN\n11     MIPGAN_I         NaN       NaN       10.0%  0.004902       NaN\n12     MIPGAN_I         NaN       NaN       20.0%  0.000000       NaN\n13     MIPGAN_I         NaN       NaN         NaN       NaN  0.024510\n14    MIPGAN_II        1.0%  0.119119         NaN       NaN       NaN\n15    MIPGAN_II       10.0%  0.015015         NaN       NaN       NaN\n16    MIPGAN_II       20.0%  0.010010         NaN       NaN       NaN\n17    MIPGAN_II         NaN       NaN        1.0%  0.166667       NaN\n18    MIPGAN_II         NaN       NaN       10.0%  0.004902       NaN\n19    MIPGAN_II         NaN       NaN       20.0%  0.000000       NaN\n20    MIPGAN_II         NaN       NaN         NaN       NaN  0.024510\n21       OpenCV        1.0%  0.954268         NaN       NaN       NaN\n22       OpenCV       10.0%  0.268293         NaN       NaN       NaN\n23       OpenCV       20.0%  0.112805         NaN       NaN       NaN\n24       OpenCV         NaN       NaN        1.0%  0.504902       NaN\n25       OpenCV         NaN       NaN       10.0%  0.205882       NaN\n26       OpenCV         NaN       NaN       20.0%  0.132353       NaN\n27       OpenCV         NaN       NaN         NaN       NaN  0.161765\n28     Webmorph        1.0%  0.988000         NaN       NaN       NaN\n29     Webmorph       10.0%  0.428000         NaN       NaN       NaN\n30     Webmorph       20.0%  0.222000         NaN       NaN       NaN\n31     Webmorph         NaN       NaN        1.0%  0.779412       NaN\n32     Webmorph         NaN       NaN       10.0%  0.328431       NaN\n33     Webmorph         NaN       NaN       20.0%  0.205882       NaN\n34     Webmorph         NaN       NaN         NaN       NaN  0.205882\n","output_type":"stream"}]}]}